{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244760bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tcn import TCN\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential , load_model , Model\n",
    "from keras.layers import Dense, Dropout , LSTM , Bidirectional ,GRU ,Flatten,Add,BatchNormalization\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras.initializers import  glorot_normal, RandomUniform\n",
    "from keras import optimizers,Input\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6f63034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 13) (144, 13) (40, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7983f645c144d0b929781bbed77e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677e777e7553497c9dfde22e1e0af541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:\n",
      "(120, 24, 12) (120,)\n",
      "Test size:\n",
      "(16, 24, 12) (16,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"station_bike _South.csv\")\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df = df.set_index(\"timestamp\")\n",
    "#df.head()\n",
    "\n",
    "df[\"hour\"] = df.index.hour\n",
    "df[\"day_of_month\"] = df.index.day\n",
    "df[\"day_of_week\"]  = df.index.dayofweek\n",
    "df[\"month\"] = df.index.month\n",
    "\n",
    "training_data_len = math.ceil(len(df) * 0.9) # taking 90% of data to train and 10% of data to test\n",
    "testing_data_len = len(df) - training_data_len\n",
    "\n",
    "time_steps = 24\n",
    "train, test = df.iloc[0:training_data_len], df.iloc[(training_data_len-time_steps):len(df)]\n",
    "print(df.shape, train.shape, test.shape)\n",
    "train_trans = train[['t1','t2', 'hum', 'wind_speed']].to_numpy()\n",
    "test_trans = test[['t1','t2', 'hum', 'wind_speed']].to_numpy()\n",
    "\n",
    "scaler = RobustScaler() # Handles outliers\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1)) # scale to (0,1)\n",
    "train.loc[:, ['t1','t2','hum', 'wind_speed']]=scaler.fit_transform(train_trans)\n",
    "test.loc[:, ['t1','t2', 'hum', 'wind_speed']]=scaler.fit_transform(test_trans)\n",
    "\n",
    "train['cnt'] = scaler.fit_transform(train[['cnt']])\n",
    "test['cnt'] = scaler.fit_transform(test[['cnt']])\n",
    "\n",
    "#Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in tqdm(range(len(train) - time_steps)):\n",
    "    x_train.append(train.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n",
    "    y_train.append(train.loc[:,'cnt'].iloc[i + time_steps])\n",
    "\n",
    "#Convert x_train and y_train to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "#Create the x_test and y_test data sets\n",
    "x_test = []\n",
    "y_test = df.loc[:,'cnt'].iloc[training_data_len:len(df)]\n",
    "\n",
    "for i in tqdm(range(len(test) - time_steps)):\n",
    "    x_test.append(test.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n",
    "    # y_test.append(test.loc[:,'cnt'].iloc[i + time_steps])\n",
    "\n",
    "#Convert x_test and y_test to numpy arrays\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# All 12 columns of the data\n",
    "print('Train size:')\n",
    "print(x_train.shape, y_train.shape)\n",
    "print('Test size:')\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4815218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 24, 12)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 24)       1800        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_3 (SeqSelfAt (None, 24, 24)       577         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 24)       0           seq_self_attention_3[0][0]       \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 24, 24)       48          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           6924        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 588)          0           dropout_3[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            589         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,940\n",
      "Trainable params: 9,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "init = glorot_normal(seed=None) # 給 GRU\n",
    "init_d = RandomUniform(minval=-0.05, maxval=0.05) # 給 Dense layer\n",
    "\n",
    "def Encoder(layer):\n",
    "    shortcut = layer\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = Add()([layer,shortcut])\n",
    "    layer = LayerNormalization()(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    \n",
    "    shortcut2 = layer\n",
    "    layer = Dense(12,kernel_initializer=init_d)(layer)\n",
    "    layer = Dropout(0.15)(layer)\n",
    "    layer = Concatenate()([layer,shortcut2])\n",
    "    output = Dense(1,kernel_initializer=init_d)(layer)\n",
    "    return output\n",
    "\n",
    "def Decoder(layer):\n",
    "    shortcut = layer\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = Add()([layer,shortcut])\n",
    "    layer = LayerNormalization()(layer)\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = LayerNormalization()(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    shortcut2 = layer\n",
    "    layer = Dense(10,kernel_initializer=init_d)(layer)\n",
    "    #layer = Dropout(0.2)(layer)\n",
    "    layer = Concatenate()([layer,shortcut2])\n",
    "    output = Dense(1,kernel_initializer=init_d)(layer)\n",
    "    return output\n",
    "\n",
    "def Bi_GRU(layer,unit):\n",
    "    output = Bidirectional(GRU(unit, dropout=0.1, recurrent_dropout=0.1, return_sequences=True,\n",
    "                            kernel_initializer=init))(layer)\n",
    "    return output\n",
    "\n",
    "#start = Input(shape = (x_train.shape[1],x_train.shape[2]))\n",
    "start = Input(shape = (x_train.shape[1:]))\n",
    "start2 = Input(shape = (x_train.shape[1:]))\n",
    "x = Bi_GRU(start,12)\n",
    "x = Encoder(x)\n",
    "\n",
    "# y = Bi_GRU(start2,8)\n",
    "# y = Decoder(y)\n",
    "\n",
    "#Merge = Add()([x,x])\n",
    "Last = Dense(1)(x)\n",
    "model = Model([start,start2] , Last)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96769b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.6046 - val_loss: 0.7048\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.4167 - val_loss: 0.6647\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0875 - val_loss: 0.5437\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0925 - val_loss: 0.7220\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.2357 - val_loss: 0.4956\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0683 - val_loss: 0.5037\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9219 - val_loss: 0.3669\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9123 - val_loss: 0.3657\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7869 - val_loss: 0.3537\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7933 - val_loss: 0.3980\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7366 - val_loss: 0.3975\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7425 - val_loss: 0.3710\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7393 - val_loss: 0.3667\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7122 - val_loss: 0.6965\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7857 - val_loss: 0.3694\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6994 - val_loss: 0.3775\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6583 - val_loss: 0.3998\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7880 - val_loss: 0.3645\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6021 - val_loss: 0.4418\n",
      "Epoch 20/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6077 - val_loss: 0.3561\n",
      "Epoch 21/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5231 - val_loss: 0.3569\n",
      "Epoch 22/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5813 - val_loss: 0.5404\n",
      "Epoch 23/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6103 - val_loss: 0.5825\n",
      "Epoch 24/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5765 - val_loss: 0.3405\n",
      "Epoch 25/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5836 - val_loss: 0.3276\n",
      "Epoch 26/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5522 - val_loss: 0.3114\n",
      "Epoch 27/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6340 - val_loss: 0.3459\n",
      "Epoch 28/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5011 - val_loss: 0.3498\n",
      "Epoch 29/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4852 - val_loss: 0.3446\n",
      "Epoch 30/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4698 - val_loss: 0.6661\n",
      "Epoch 31/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6206 - val_loss: 0.3837\n",
      "Epoch 32/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5078 - val_loss: 0.4048\n",
      "Epoch 33/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5087 - val_loss: 0.2949\n",
      "Epoch 34/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6164 - val_loss: 0.2910\n",
      "Epoch 35/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5096 - val_loss: 0.2646\n",
      "Epoch 36/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5690 - val_loss: 0.2660\n",
      "Epoch 37/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4596 - val_loss: 0.3404\n",
      "Epoch 38/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5417 - val_loss: 0.3827\n",
      "Epoch 39/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4431 - val_loss: 0.3353\n",
      "Epoch 40/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3912 - val_loss: 0.5615\n",
      "Epoch 41/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5452 - val_loss: 0.5832\n",
      "Epoch 42/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5643 - val_loss: 0.3098\n",
      "Epoch 43/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3467 - val_loss: 0.3399\n",
      "Epoch 44/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4724 - val_loss: 0.3557\n",
      "Epoch 45/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.5266 - val_loss: 0.7763\n",
      "Epoch 46/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3821 - val_loss: 0.4879\n",
      "Epoch 47/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4147 - val_loss: 0.5099\n",
      "Epoch 48/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4490 - val_loss: 0.6780\n",
      "Epoch 49/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4174 - val_loss: 0.4100\n",
      "Epoch 50/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.3155 - val_loss: 0.3439\n",
      "Epoch 51/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3392 - val_loss: 0.2802\n",
      "Epoch 52/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3328 - val_loss: 0.3030\n",
      "Epoch 53/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3726 - val_loss: 0.3936\n",
      "Epoch 54/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3975 - val_loss: 0.2804\n",
      "Epoch 55/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3338 - val_loss: 0.4370\n",
      "Epoch 56/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3399 - val_loss: 0.3102\n",
      "Epoch 57/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3555 - val_loss: 0.3589\n",
      "Epoch 58/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3072 - val_loss: 0.6175\n",
      "Epoch 59/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3377 - val_loss: 0.3128\n",
      "Epoch 60/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3974 - val_loss: 0.5247\n",
      "Epoch 61/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3296 - val_loss: 0.6169\n",
      "Epoch 62/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2637 - val_loss: 0.3206\n",
      "Epoch 63/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4285 - val_loss: 0.2798\n",
      "Epoch 64/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3390 - val_loss: 0.2654\n",
      "Epoch 65/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3449 - val_loss: 0.2873\n",
      "Epoch 66/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3561 - val_loss: 0.3470\n",
      "Epoch 67/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2938 - val_loss: 0.2750\n",
      "Epoch 68/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3106 - val_loss: 0.2985\n",
      "Epoch 69/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3041 - val_loss: 0.4321\n",
      "Epoch 70/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3789 - val_loss: 0.3482\n",
      "Epoch 71/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3032 - val_loss: 0.4522\n",
      "Epoch 72/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3640 - val_loss: 0.3124\n",
      "Epoch 73/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3129 - val_loss: 0.3023\n",
      "Epoch 74/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2949 - val_loss: 0.3756\n",
      "Epoch 75/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3685 - val_loss: 0.1985\n",
      "Epoch 76/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3889 - val_loss: 0.9581\n",
      "Epoch 77/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4260 - val_loss: 0.9440\n",
      "Epoch 78/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3438 - val_loss: 0.4674\n",
      "Epoch 79/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2603 - val_loss: 0.1987\n",
      "Epoch 80/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3255 - val_loss: 0.1743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4199 - val_loss: 0.2039\n",
      "Epoch 82/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2386 - val_loss: 0.2937\n",
      "Epoch 83/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3458 - val_loss: 0.2961\n",
      "Epoch 84/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3434 - val_loss: 0.1751\n",
      "Epoch 85/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2553 - val_loss: 0.2276\n",
      "Epoch 86/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2857 - val_loss: 0.2640\n",
      "Epoch 87/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2956 - val_loss: 0.2192\n",
      "Epoch 88/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3428 - val_loss: 0.6106\n",
      "Epoch 89/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2644 - val_loss: 0.2452\n",
      "Epoch 90/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2662 - val_loss: 0.5012\n",
      "Epoch 91/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2541 - val_loss: 0.2661\n",
      "Epoch 92/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2423 - val_loss: 0.2656\n",
      "Epoch 93/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2990 - val_loss: 0.4578\n",
      "Epoch 94/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2349 - val_loss: 0.3175\n",
      "Epoch 95/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2756 - val_loss: 0.3220\n",
      "Epoch 96/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.2966 - val_loss: 0.4140\n",
      "Epoch 97/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3088 - val_loss: 0.1797\n",
      "Epoch 98/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3963 - val_loss: 0.2247\n",
      "Epoch 99/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3355 - val_loss: 0.3139\n",
      "Epoch 100/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2166 - val_loss: 0.1978\n",
      "Epoch 101/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2598 - val_loss: 0.1971\n",
      "Epoch 102/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2544 - val_loss: 0.2774\n",
      "Epoch 103/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2216 - val_loss: 0.1912\n",
      "Epoch 104/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1903 - val_loss: 0.1875\n",
      "Epoch 105/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2578 - val_loss: 0.2596\n",
      "Epoch 106/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3167 - val_loss: 0.2751\n",
      "Epoch 107/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2194 - val_loss: 0.1749\n",
      "Epoch 108/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2289 - val_loss: 0.1639\n",
      "Epoch 109/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1900 - val_loss: 0.2245\n",
      "Epoch 110/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2417 - val_loss: 0.1793\n",
      "Epoch 111/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2234 - val_loss: 0.2307\n",
      "Epoch 112/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2482 - val_loss: 0.1813\n",
      "Epoch 113/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2311 - val_loss: 0.4087\n",
      "Epoch 114/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3590 - val_loss: 0.2814\n",
      "Epoch 115/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2567 - val_loss: 0.4519\n",
      "Epoch 116/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2184 - val_loss: 0.2139\n",
      "Epoch 117/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1958 - val_loss: 0.1444\n",
      "Epoch 118/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2294 - val_loss: 0.1762\n",
      "Epoch 119/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2110 - val_loss: 0.1741\n",
      "Epoch 120/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2122 - val_loss: 0.2546\n",
      "Epoch 121/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2389 - val_loss: 0.2361\n",
      "Epoch 122/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2116 - val_loss: 0.1788\n",
      "Epoch 123/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2107 - val_loss: 0.3451\n",
      "Epoch 124/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1935 - val_loss: 0.3296\n",
      "Epoch 125/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2778 - val_loss: 0.2465\n",
      "Epoch 126/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2737 - val_loss: 0.1326\n",
      "Epoch 127/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2134 - val_loss: 0.2333\n",
      "Epoch 128/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1878 - val_loss: 0.1480\n",
      "Epoch 129/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1866 - val_loss: 0.2288\n",
      "Epoch 130/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1723 - val_loss: 0.3070\n",
      "Epoch 131/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2067 - val_loss: 0.1770\n",
      "Epoch 132/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1724 - val_loss: 0.2622\n",
      "Epoch 133/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1689 - val_loss: 0.1860\n",
      "Epoch 134/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1960 - val_loss: 0.2406\n",
      "Epoch 135/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2308 - val_loss: 0.3005\n",
      "Epoch 136/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2533 - val_loss: 0.3146\n",
      "Epoch 137/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2360 - val_loss: 0.2084\n",
      "Epoch 138/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2092 - val_loss: 0.2847\n",
      "Epoch 139/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1981 - val_loss: 0.2322\n",
      "Epoch 140/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2853 - val_loss: 0.1790\n",
      "Epoch 141/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1856 - val_loss: 0.2447\n",
      "Epoch 142/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2233 - val_loss: 0.2634\n",
      "Epoch 143/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1666 - val_loss: 0.2192\n",
      "Epoch 144/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1733 - val_loss: 0.3564\n",
      "Epoch 145/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1642 - val_loss: 0.2331\n",
      "Epoch 146/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1866 - val_loss: 0.1517\n",
      "Epoch 147/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2030 - val_loss: 0.2837\n",
      "Epoch 148/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1585 - val_loss: 0.1953\n",
      "Epoch 149/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1945 - val_loss: 0.2402\n",
      "Epoch 150/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2412 - val_loss: 0.3506\n",
      "Epoch 151/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1517 - val_loss: 0.2793\n",
      "Epoch 152/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1998 - val_loss: 0.2590\n",
      "Epoch 153/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1497 - val_loss: 0.4020\n",
      "Epoch 154/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1658 - val_loss: 0.2182\n",
      "Epoch 155/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2074 - val_loss: 0.1992\n",
      "Epoch 156/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2262 - val_loss: 0.2378\n",
      "Epoch 157/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1552 - val_loss: 0.1633\n",
      "Epoch 158/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2007 - val_loss: 0.2602\n",
      "Epoch 159/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1834 - val_loss: 0.3352\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1819 - val_loss: 0.1533\n",
      "Epoch 161/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2320 - val_loss: 0.2062\n",
      "Epoch 162/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2044 - val_loss: 0.1543\n",
      "Epoch 163/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1939 - val_loss: 0.4192\n",
      "Epoch 164/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1838 - val_loss: 0.4897\n",
      "Epoch 165/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2852 - val_loss: 0.1790\n",
      "Epoch 166/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1597 - val_loss: 0.3495\n",
      "Epoch 167/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1459 - val_loss: 0.4531\n",
      "Epoch 168/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2082 - val_loss: 0.2456\n",
      "Epoch 169/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2074 - val_loss: 0.1201\n",
      "Epoch 170/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2381 - val_loss: 0.1317\n",
      "Epoch 171/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1987 - val_loss: 0.2461\n",
      "Epoch 172/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2144 - val_loss: 0.4818\n",
      "Epoch 173/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2114 - val_loss: 0.3363\n",
      "Epoch 174/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2128 - val_loss: 0.3736\n",
      "Epoch 175/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1850 - val_loss: 0.2621\n",
      "Epoch 176/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1722 - val_loss: 0.1925\n",
      "Epoch 177/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1849 - val_loss: 0.1365\n",
      "Epoch 178/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1559 - val_loss: 0.2278\n",
      "Epoch 179/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2865 - val_loss: 0.2126\n",
      "Epoch 180/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1879 - val_loss: 0.2853\n",
      "Epoch 181/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1607 - val_loss: 0.2967\n",
      "Epoch 182/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1376 - val_loss: 0.2970\n",
      "Epoch 183/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1437 - val_loss: 0.1472\n",
      "Epoch 184/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1702 - val_loss: 0.2834\n",
      "Epoch 185/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1921 - val_loss: 0.1829\n",
      "Epoch 186/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1639 - val_loss: 0.1345\n",
      "Epoch 187/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1850 - val_loss: 0.2755\n",
      "Epoch 188/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1416 - val_loss: 0.1836\n",
      "Epoch 189/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2123 - val_loss: 0.1497\n",
      "Epoch 190/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1525 - val_loss: 0.1693\n",
      "Epoch 191/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1655 - val_loss: 0.1660\n",
      "Epoch 192/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1362 - val_loss: 0.2351\n",
      "Epoch 193/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1800 - val_loss: 0.1374\n",
      "Epoch 194/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2233 - val_loss: 0.2119\n",
      "Epoch 195/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1916 - val_loss: 0.2037\n",
      "Epoch 196/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1321 - val_loss: 0.1644\n",
      "Epoch 197/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2377 - val_loss: 0.2757\n",
      "Epoch 198/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2180 - val_loss: 0.1992\n",
      "Epoch 199/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1488 - val_loss: 0.4565\n",
      "Epoch 200/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1750 - val_loss: 0.4339\n",
      "Epoch 201/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1978 - val_loss: 0.2105\n",
      "Epoch 202/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1320 - val_loss: 0.2496\n",
      "Epoch 203/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1237 - val_loss: 0.2106\n",
      "Epoch 204/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1596 - val_loss: 0.1535\n",
      "Epoch 205/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1338 - val_loss: 0.2842\n",
      "Epoch 206/500\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.106 - 1s 7ms/step - loss: 0.1046 - val_loss: 0.3452\n",
      "Epoch 207/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1791 - val_loss: 0.1439\n",
      "Epoch 208/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1544 - val_loss: 0.2444\n",
      "Epoch 209/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1965 - val_loss: 0.5347\n",
      "Epoch 210/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1969 - val_loss: 0.2967\n",
      "Epoch 211/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1032 - val_loss: 0.1822\n",
      "Epoch 212/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1368 - val_loss: 0.2287\n",
      "Epoch 213/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1341 - val_loss: 0.3209\n",
      "Epoch 214/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1471 - val_loss: 0.1957\n",
      "Epoch 215/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1473 - val_loss: 0.2114\n",
      "Epoch 216/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1014 - val_loss: 0.1998\n",
      "Epoch 217/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1374 - val_loss: 0.2918\n",
      "Epoch 218/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1331 - val_loss: 0.1522\n",
      "Epoch 219/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1677 - val_loss: 0.1278\n",
      "Epoch 220/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1882 - val_loss: 0.2526\n",
      "Epoch 221/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1653 - val_loss: 0.1791\n",
      "Epoch 222/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1809 - val_loss: 0.3198\n",
      "Epoch 223/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2191 - val_loss: 0.3059\n",
      "Epoch 224/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1454 - val_loss: 0.3136\n",
      "Epoch 225/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1484 - val_loss: 0.2828\n",
      "Epoch 226/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1304 - val_loss: 0.1476\n",
      "Epoch 227/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1163 - val_loss: 0.1994\n",
      "Epoch 228/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2259 - val_loss: 0.1767\n",
      "Epoch 229/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1975 - val_loss: 0.3297\n",
      "Epoch 230/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1480 - val_loss: 0.4005\n",
      "Epoch 231/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2098 - val_loss: 0.2020\n",
      "Epoch 232/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1190 - val_loss: 0.3957\n",
      "Epoch 233/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1268 - val_loss: 0.3309\n",
      "Epoch 234/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1271 - val_loss: 0.1669\n",
      "Epoch 235/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0995 - val_loss: 0.2613\n",
      "Epoch 236/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1852 - val_loss: 0.1380\n",
      "Epoch 237/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1118 - val_loss: 0.2429\n",
      "Epoch 238/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1163 - val_loss: 0.2269\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1078 - val_loss: 0.2328\n",
      "Epoch 240/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1170 - val_loss: 0.3323\n",
      "Epoch 241/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1283 - val_loss: 0.1713\n",
      "Epoch 242/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1079 - val_loss: 0.3249\n",
      "Epoch 243/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1065 - val_loss: 0.3606\n",
      "Epoch 244/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1725 - val_loss: 0.1893\n",
      "Epoch 245/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1364 - val_loss: 0.5748\n",
      "Epoch 246/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1699 - val_loss: 0.1791\n",
      "Epoch 247/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1008 - val_loss: 0.2347\n",
      "Epoch 248/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1324 - val_loss: 0.4378\n",
      "Epoch 249/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1626 - val_loss: 0.2676\n",
      "Epoch 250/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1394 - val_loss: 0.1652\n",
      "Epoch 251/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1347 - val_loss: 0.2570\n",
      "Epoch 252/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1208 - val_loss: 0.2380\n",
      "Epoch 253/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1673 - val_loss: 0.3129\n",
      "Epoch 254/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1078 - val_loss: 0.1737\n",
      "Epoch 255/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1108 - val_loss: 0.2565\n",
      "Epoch 256/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1324 - val_loss: 0.2061\n",
      "Epoch 257/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1042 - val_loss: 0.3277\n",
      "Epoch 258/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1118 - val_loss: 0.2420\n",
      "Epoch 259/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1007 - val_loss: 0.3420\n",
      "Epoch 260/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1004 - val_loss: 0.2037\n",
      "Epoch 261/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0853 - val_loss: 0.1621\n",
      "Epoch 262/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0993 - val_loss: 0.1590\n",
      "Epoch 263/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1125 - val_loss: 0.2109\n",
      "Epoch 264/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1372 - val_loss: 0.2453\n",
      "Epoch 265/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1150 - val_loss: 0.4636\n",
      "Epoch 266/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1393 - val_loss: 0.4182\n",
      "Epoch 267/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0996 - val_loss: 0.2235\n",
      "Epoch 268/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0911 - val_loss: 0.2524\n",
      "Epoch 269/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1223 - val_loss: 0.1356\n",
      "Epoch 270/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1497 - val_loss: 0.2409\n",
      "Epoch 271/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2026 - val_loss: 1.2142\n",
      "Epoch 272/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1641 - val_loss: 0.3835\n",
      "Epoch 273/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1190 - val_loss: 0.1615\n",
      "Epoch 274/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0999 - val_loss: 0.2530\n",
      "Epoch 275/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1306 - val_loss: 0.1961\n",
      "Epoch 276/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1235 - val_loss: 0.1682\n",
      "Epoch 277/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1293 - val_loss: 0.2644\n",
      "Epoch 278/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1028 - val_loss: 0.3484\n",
      "Epoch 279/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1169 - val_loss: 0.5012\n",
      "Epoch 280/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1741 - val_loss: 0.2784\n",
      "Epoch 281/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1727 - val_loss: 0.1893\n",
      "Epoch 282/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1298 - val_loss: 0.1436\n",
      "Epoch 283/500\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.106 - 1s 7ms/step - loss: 0.1106 - val_loss: 0.2854\n",
      "Epoch 284/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0943 - val_loss: 0.2462\n",
      "Epoch 285/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1060 - val_loss: 0.2090\n",
      "Epoch 286/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0785 - val_loss: 0.2653\n",
      "Epoch 287/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1014 - val_loss: 0.2275\n",
      "Epoch 288/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0878 - val_loss: 0.1437\n",
      "Epoch 289/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1359 - val_loss: 0.1745\n",
      "Epoch 290/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1236 - val_loss: 0.2984\n",
      "Epoch 291/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1342 - val_loss: 0.1684\n",
      "Epoch 292/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1106 - val_loss: 0.1193\n",
      "Epoch 293/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0997 - val_loss: 0.2104\n",
      "Epoch 294/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0752 - val_loss: 0.1970\n",
      "Epoch 295/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0829 - val_loss: 0.2532\n",
      "Epoch 296/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0878 - val_loss: 0.1498\n",
      "Epoch 297/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0817 - val_loss: 0.1355\n",
      "Epoch 298/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1288 - val_loss: 0.1319\n",
      "Epoch 299/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1060 - val_loss: 0.4014\n",
      "Epoch 300/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0848 - val_loss: 0.1792\n",
      "Epoch 301/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1196 - val_loss: 0.1100\n",
      "Epoch 302/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0989 - val_loss: 0.1974\n",
      "Epoch 303/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1448 - val_loss: 0.2957\n",
      "Epoch 304/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0984 - val_loss: 0.1523\n",
      "Epoch 305/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1301 - val_loss: 0.4448\n",
      "Epoch 306/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0700 - val_loss: 0.3923\n",
      "Epoch 307/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1169 - val_loss: 0.3198\n",
      "Epoch 308/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0945 - val_loss: 0.2626\n",
      "Epoch 309/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0954 - val_loss: 0.2481\n",
      "Epoch 310/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0940 - val_loss: 0.2261\n",
      "Epoch 311/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1307 - val_loss: 0.2186\n",
      "Epoch 312/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0798 - val_loss: 0.1717\n",
      "Epoch 313/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0744 - val_loss: 0.1482\n",
      "Epoch 314/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1425 - val_loss: 0.1748\n",
      "Epoch 315/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1036 - val_loss: 0.2001\n",
      "Epoch 316/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0969 - val_loss: 0.3562\n",
      "Epoch 317/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0918 - val_loss: 0.1490\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1133 - val_loss: 0.1653\n",
      "Epoch 319/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0848 - val_loss: 0.2547\n",
      "Epoch 320/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0677 - val_loss: 0.1730\n",
      "Epoch 321/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0655 - val_loss: 0.2422\n",
      "Epoch 322/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0856 - val_loss: 0.2586\n",
      "Epoch 323/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0750 - val_loss: 0.1572\n",
      "Epoch 324/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0690 - val_loss: 0.1649\n",
      "Epoch 325/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1112 - val_loss: 0.2257\n",
      "Epoch 326/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0760 - val_loss: 0.2516\n",
      "Epoch 327/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0810 - val_loss: 0.2464\n",
      "Epoch 328/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0922 - val_loss: 0.3531\n",
      "Epoch 329/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0719 - val_loss: 0.2432\n",
      "Epoch 330/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1680 - val_loss: 0.2705\n",
      "Epoch 331/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1149 - val_loss: 0.5313\n",
      "Epoch 332/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1323 - val_loss: 0.4417\n",
      "Epoch 333/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1306 - val_loss: 0.2889\n",
      "Epoch 334/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0794 - val_loss: 0.2113\n",
      "Epoch 335/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1119 - val_loss: 0.1549\n",
      "Epoch 336/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1144 - val_loss: 0.1503\n",
      "Epoch 337/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0677 - val_loss: 0.2193\n",
      "Epoch 338/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0969 - val_loss: 0.2427\n",
      "Epoch 339/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.3073\n",
      "Epoch 340/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0845 - val_loss: 0.3480\n",
      "Epoch 341/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0894 - val_loss: 0.1655\n",
      "Epoch 342/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0670 - val_loss: 0.2292\n",
      "Epoch 343/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0951 - val_loss: 0.1506\n",
      "Epoch 344/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0866 - val_loss: 0.2850\n",
      "Epoch 345/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1354 - val_loss: 0.5554\n",
      "Epoch 346/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0978 - val_loss: 0.2382\n",
      "Epoch 347/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1199 - val_loss: 0.0968\n",
      "Epoch 348/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1085 - val_loss: 0.2113\n",
      "Epoch 349/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0903 - val_loss: 0.3185\n",
      "Epoch 350/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1000 - val_loss: 0.2254\n",
      "Epoch 351/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1008 - val_loss: 0.1670\n",
      "Epoch 352/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0845 - val_loss: 0.2795\n",
      "Epoch 353/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0889 - val_loss: 0.2128\n",
      "Epoch 354/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0783 - val_loss: 0.3014\n",
      "Epoch 355/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0656 - val_loss: 0.1970\n",
      "Epoch 356/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.2635\n",
      "Epoch 357/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0958 - val_loss: 0.2462\n",
      "Epoch 358/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0889 - val_loss: 0.2535\n",
      "Epoch 359/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0791 - val_loss: 0.0987\n",
      "Epoch 360/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0688 - val_loss: 0.2527\n",
      "Epoch 361/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0917 - val_loss: 0.3135\n",
      "Epoch 362/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0797 - val_loss: 0.2315\n",
      "Epoch 363/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0955 - val_loss: 0.2399\n",
      "Epoch 364/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0723 - val_loss: 0.1950\n",
      "Epoch 365/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0829 - val_loss: 0.2672\n",
      "Epoch 366/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0988 - val_loss: 0.2152\n",
      "Epoch 367/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0675 - val_loss: 0.1051\n",
      "Epoch 368/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1168 - val_loss: 0.1975\n",
      "Epoch 369/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0587 - val_loss: 0.2595\n",
      "Epoch 370/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0507 - val_loss: 0.3122\n",
      "Epoch 371/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1475 - val_loss: 0.1302\n",
      "Epoch 372/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1212 - val_loss: 0.4092\n",
      "Epoch 373/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0905 - val_loss: 0.2289\n",
      "Epoch 374/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0731 - val_loss: 0.4411\n",
      "Epoch 375/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0692 - val_loss: 0.1899\n",
      "Epoch 376/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0824 - val_loss: 0.3426\n",
      "Epoch 377/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0787 - val_loss: 0.2242\n",
      "Epoch 378/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1125 - val_loss: 0.3169\n",
      "Epoch 379/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0933 - val_loss: 0.4004\n",
      "Epoch 380/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0800 - val_loss: 0.3234\n",
      "Epoch 381/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0742 - val_loss: 0.2374\n",
      "Epoch 382/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0590 - val_loss: 0.2343\n",
      "Epoch 383/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0817 - val_loss: 0.2340\n",
      "Epoch 384/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0771 - val_loss: 0.3816\n",
      "Epoch 385/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0713 - val_loss: 0.2146\n",
      "Epoch 386/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0556 - val_loss: 0.1276\n",
      "Epoch 387/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1150 - val_loss: 0.3320\n",
      "Epoch 388/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0870 - val_loss: 0.2505\n",
      "Epoch 389/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0542 - val_loss: 0.1758\n",
      "Epoch 390/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0714 - val_loss: 0.3369\n",
      "Epoch 391/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0666 - val_loss: 0.1851\n",
      "Epoch 392/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0993 - val_loss: 0.3779\n",
      "Epoch 393/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0676 - val_loss: 0.2269\n",
      "Epoch 394/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0545 - val_loss: 0.2112\n",
      "Epoch 395/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0909 - val_loss: 0.2022\n",
      "Epoch 396/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0523 - val_loss: 0.2527\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0881 - val_loss: 0.4342\n",
      "Epoch 398/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1200 - val_loss: 0.3210\n",
      "Epoch 399/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0681 - val_loss: 0.2874\n",
      "Epoch 400/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0505 - val_loss: 0.1934\n",
      "Epoch 401/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1058 - val_loss: 0.3702\n",
      "Epoch 402/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0838 - val_loss: 0.3208\n",
      "Epoch 403/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0630 - val_loss: 0.2846\n",
      "Epoch 404/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0536 - val_loss: 0.1506\n",
      "Epoch 405/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0672 - val_loss: 0.1494\n",
      "Epoch 406/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0965 - val_loss: 0.2036\n",
      "Epoch 407/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0660 - val_loss: 0.2055\n",
      "Epoch 408/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0533 - val_loss: 0.2686\n",
      "Epoch 409/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0724 - val_loss: 0.1827\n",
      "Epoch 410/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0629 - val_loss: 0.3918\n",
      "Epoch 411/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0844 - val_loss: 0.2464\n",
      "Epoch 412/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0656 - val_loss: 0.1518\n",
      "Epoch 413/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0612 - val_loss: 0.3093\n",
      "Epoch 414/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0541 - val_loss: 0.2205\n",
      "Epoch 415/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0585 - val_loss: 0.1015\n",
      "Epoch 416/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0758 - val_loss: 0.2327\n",
      "Epoch 417/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0769 - val_loss: 0.3521\n",
      "Epoch 418/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0615 - val_loss: 0.2287\n",
      "Epoch 419/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0833 - val_loss: 0.2987\n",
      "Epoch 420/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0648 - val_loss: 0.3180\n",
      "Epoch 421/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0605 - val_loss: 0.2429\n",
      "Epoch 422/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0686 - val_loss: 0.1443\n",
      "Epoch 423/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0859 - val_loss: 0.2570\n",
      "Epoch 424/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0599 - val_loss: 0.2214\n",
      "Epoch 425/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0731 - val_loss: 0.1903\n",
      "Epoch 426/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0746 - val_loss: 0.2225\n",
      "Epoch 427/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0483 - val_loss: 0.1640\n",
      "Epoch 428/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2637 - val_loss: 0.2639\n",
      "Epoch 429/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1473 - val_loss: 0.1156\n",
      "Epoch 430/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1789 - val_loss: 0.3854\n",
      "Epoch 431/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1209 - val_loss: 0.4348\n",
      "Epoch 432/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1471 - val_loss: 0.1958\n",
      "Epoch 433/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0968 - val_loss: 0.3218\n",
      "Epoch 434/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0782 - val_loss: 0.2131\n",
      "Epoch 435/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0755 - val_loss: 0.2385\n",
      "Epoch 436/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0724 - val_loss: 0.2195\n",
      "Epoch 437/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0502 - val_loss: 0.1978\n",
      "Epoch 438/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.2450\n",
      "Epoch 439/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0709 - val_loss: 0.2110\n",
      "Epoch 440/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0480 - val_loss: 0.1988\n",
      "Epoch 441/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0588 - val_loss: 0.2770\n",
      "Epoch 442/500\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.072 - 1s 7ms/step - loss: 0.0748 - val_loss: 0.2438\n",
      "Epoch 443/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0639 - val_loss: 0.1647\n",
      "Epoch 444/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0616 - val_loss: 0.2741\n",
      "Epoch 445/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.1818\n",
      "Epoch 446/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0740 - val_loss: 0.4134\n",
      "Epoch 447/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0511 - val_loss: 0.3128\n",
      "Epoch 448/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0601 - val_loss: 0.2102\n",
      "Epoch 449/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0362 - val_loss: 0.2275\n",
      "Epoch 450/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0599 - val_loss: 0.2073\n",
      "Epoch 451/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0756 - val_loss: 0.3467\n",
      "Epoch 452/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0489 - val_loss: 0.1682\n",
      "Epoch 453/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.1567\n",
      "Epoch 454/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0895 - val_loss: 0.2202\n",
      "Epoch 455/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0636 - val_loss: 0.3013\n",
      "Epoch 456/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0680 - val_loss: 0.2192\n",
      "Epoch 457/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0536 - val_loss: 0.1452\n",
      "Epoch 458/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0507 - val_loss: 0.2285\n",
      "Epoch 459/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0601 - val_loss: 0.2160\n",
      "Epoch 460/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0611 - val_loss: 0.2022\n",
      "Epoch 461/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.2296\n",
      "Epoch 462/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0483 - val_loss: 0.2194\n",
      "Epoch 463/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0678 - val_loss: 0.2642\n",
      "Epoch 464/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.1999\n",
      "Epoch 465/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0564 - val_loss: 0.2661\n",
      "Epoch 466/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0527 - val_loss: 0.2032\n",
      "Epoch 467/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0476 - val_loss: 0.1973\n",
      "Epoch 468/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0570 - val_loss: 0.4140\n",
      "Epoch 469/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0694 - val_loss: 0.1288\n",
      "Epoch 470/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1710 - val_loss: 0.3366\n",
      "Epoch 471/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1046 - val_loss: 0.1880\n",
      "Epoch 472/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1074 - val_loss: 0.2533\n",
      "Epoch 473/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0851 - val_loss: 0.1625\n",
      "Epoch 474/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0820 - val_loss: 0.3167\n",
      "Epoch 475/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0613 - val_loss: 0.2937\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0574 - val_loss: 0.1274\n",
      "Epoch 477/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0990 - val_loss: 0.3252\n",
      "Epoch 478/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0658 - val_loss: 0.1796\n",
      "Epoch 479/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0951 - val_loss: 0.2280\n",
      "Epoch 480/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0759 - val_loss: 0.3418\n",
      "Epoch 481/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0810 - val_loss: 0.1613\n",
      "Epoch 482/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0588 - val_loss: 0.3400\n",
      "Epoch 483/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0536 - val_loss: 0.1790\n",
      "Epoch 484/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0852 - val_loss: 0.1736\n",
      "Epoch 485/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0587 - val_loss: 0.3601\n",
      "Epoch 486/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0819 - val_loss: 0.2085\n",
      "Epoch 487/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0632 - val_loss: 0.1546\n",
      "Epoch 488/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0620 - val_loss: 0.3772\n",
      "Epoch 489/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0467 - val_loss: 0.2699\n",
      "Epoch 490/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0408 - val_loss: 0.1375\n",
      "Epoch 491/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1370 - val_loss: 0.4354\n",
      "Epoch 492/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1486 - val_loss: 0.2868\n",
      "Epoch 493/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0696 - val_loss: 0.4662\n",
      "Epoch 494/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1359 - val_loss: 0.2462\n",
      "Epoch 495/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0825 - val_loss: 0.2590\n",
      "Epoch 496/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0677 - val_loss: 0.2926\n",
      "Epoch 497/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0660 - val_loss: 0.2405\n",
      "Epoch 498/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0433 - val_loss: 0.3588\n",
      "Epoch 499/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0507 - val_loss: 0.2113\n",
      "Epoch 500/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0451 - val_loss: 0.3149\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 24, 12)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 24)       1800        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_3 (SeqSelfAt (None, 24, 24)       577         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 24)       0           seq_self_attention_3[0][0]       \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 24, 24)       48          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           6924        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 588)          0           dropout_3[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            589         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,940\n",
      "Trainable params: 9,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Predict time:  0.36017370223999023\n",
      "RMSE:  4.7313811105292\n",
      "RMSE2:  1.974571793818967\n",
      "MAE:  3.430992392698924\n",
      "MAE2:  3.430992392698924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse score')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=0.001,decay = 0.0001)\n",
    "print('Train...')\n",
    "# model.compile(optimizer = opt , loss=\"mse\")\n",
    "model.compile(optimizer = \"adam\" , loss=\"mse\")\n",
    "history = model.fit([x_train,x_train], y_train, epochs = 500, batch_size=8, validation_split=0.1, shuffle=True)\n",
    "# history = model.fit(x_train, y_train, epochs = 500, batch_size=6, validation_split=0.1, shuffle=True)\n",
    "model.summary()\n",
    "#Save Model\n",
    "model.save('GRU_Single_Attention_model_South.h5')  # creates a HDF5 file \n",
    "del model\n",
    "\n",
    "custom_ob = {'LayerNormalization': LayerNormalization , 'SeqSelfAttention':SeqSelfAttention}\n",
    "model = load_model('GRU_Single_Attention_model_South.h5', custom_objects=custom_ob)\n",
    "t1 = time.time()\n",
    "# y_pred = model.predict([x_test,x_test])\n",
    "y_pred2 = model.predict(x_test)\n",
    "y_pred = model.predict(x_train)\n",
    "t2 = time.time()\n",
    "print('Predict time: ',t2-t1)\n",
    "y_pred = scaler.inverse_transform(y_pred)#Undo scaling\n",
    "rmse_lstm2 = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print('RMSE: ',rmse_lstm)\n",
    "print('RMSE2: ',rmse_lstm2)\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('MAE: ',mae)\n",
    "print('MAE2: ',mae)\n",
    "# r22 =  r2_score(y_test, y_pred2)\n",
    "# r2 =  r2_score(y_train, y_pred)\n",
    "# print('R-square: ',r2)\n",
    "# print('R-square2: ',r22)\n",
    "\n",
    "# n = len(y_test)\n",
    "# p = 12\n",
    "# Adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "# Adj_r22 = 1-(1-r22)*(n-1)/(n-p-1)\n",
    "# print('Adj R-square: ',Adj_r2)\n",
    "# print('Adj R-square2: ',Adj_r22)\n",
    "\n",
    "plt.plot(history.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"No. Of Epochs\")\n",
    "plt.ylabel(\"mse score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e16565f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/200\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 1.9279 - val_loss: 1.7611\n",
      "Epoch 2/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.8747 - val_loss: 1.6586\n",
      "Epoch 3/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.8092 - val_loss: 1.5662\n",
      "Epoch 4/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.7356 - val_loss: 1.4701\n",
      "Epoch 5/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.7080 - val_loss: 1.3880\n",
      "Epoch 6/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.6591 - val_loss: 1.3186\n",
      "Epoch 7/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.6137 - val_loss: 1.2542\n",
      "Epoch 8/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.5860 - val_loss: 1.1947\n",
      "Epoch 9/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.5408 - val_loss: 1.1428\n",
      "Epoch 10/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.4710 - val_loss: 1.1007\n",
      "Epoch 11/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.4410 - val_loss: 1.0558\n",
      "Epoch 12/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.4158 - val_loss: 1.0233\n",
      "Epoch 13/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.4050 - val_loss: 0.9899\n",
      "Epoch 14/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.3501 - val_loss: 0.9572\n",
      "Epoch 15/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.3248 - val_loss: 0.9288\n",
      "Epoch 16/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.2673 - val_loss: 0.8995\n",
      "Epoch 17/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.2912 - val_loss: 0.8757\n",
      "Epoch 18/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.2721 - val_loss: 0.8541\n",
      "Epoch 19/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.2178 - val_loss: 0.8309\n",
      "Epoch 20/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.2295 - val_loss: 0.8072\n",
      "Epoch 21/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.1896 - val_loss: 0.7907\n",
      "Epoch 22/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.1781 - val_loss: 0.7792\n",
      "Epoch 23/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.1591 - val_loss: 0.7589\n",
      "Epoch 24/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.1476 - val_loss: 0.7474\n",
      "Epoch 25/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.1125 - val_loss: 0.7391\n",
      "Epoch 26/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.1099 - val_loss: 0.7309\n",
      "Epoch 27/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.0845 - val_loss: 0.7227\n",
      "Epoch 28/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.0701 - val_loss: 0.7152\n",
      "Epoch 29/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.0900 - val_loss: 0.7196\n",
      "Epoch 30/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.0397 - val_loss: 0.6915\n",
      "Epoch 31/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.0333 - val_loss: 0.6628\n",
      "Epoch 32/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.0536 - val_loss: 0.6679\n",
      "Epoch 33/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 1.0042 - val_loss: 0.6610\n",
      "Epoch 34/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.9963 - val_loss: 0.6756\n",
      "Epoch 35/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.9825 - val_loss: 0.6820\n",
      "Epoch 36/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.9839 - val_loss: 0.6732\n",
      "Epoch 37/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.9471 - val_loss: 0.6513\n",
      "Epoch 38/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9649 - val_loss: 0.6416\n",
      "Epoch 39/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.9482 - val_loss: 0.6707\n",
      "Epoch 40/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.9095 - val_loss: 0.6739\n",
      "Epoch 41/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.9240 - val_loss: 0.6557\n",
      "Epoch 42/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8770 - val_loss: 0.6628\n",
      "Epoch 43/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.8827 - val_loss: 0.6283\n",
      "Epoch 44/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.8805 - val_loss: 0.5980\n",
      "Epoch 45/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.8424 - val_loss: 0.5945\n",
      "Epoch 46/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8627 - val_loss: 0.6498\n",
      "Epoch 47/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8445 - val_loss: 0.6254\n",
      "Epoch 48/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8274 - val_loss: 0.6444\n",
      "Epoch 49/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8273 - val_loss: 0.6402\n",
      "Epoch 50/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8069 - val_loss: 0.5814\n",
      "Epoch 51/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7659 - val_loss: 0.5455\n",
      "Epoch 52/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7747 - val_loss: 0.6483\n",
      "Epoch 53/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7732 - val_loss: 0.5810\n",
      "Epoch 54/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7483 - val_loss: 0.5860\n",
      "Epoch 55/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7392 - val_loss: 0.5846\n",
      "Epoch 56/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7043 - val_loss: 0.6490\n",
      "Epoch 57/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7275 - val_loss: 0.4798\n",
      "Epoch 58/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7286 - val_loss: 0.5920\n",
      "Epoch 59/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7070 - val_loss: 0.6168\n",
      "Epoch 60/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7158 - val_loss: 0.5786\n",
      "Epoch 61/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6706 - val_loss: 0.7256\n",
      "Epoch 62/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6971 - val_loss: 0.7127\n",
      "Epoch 63/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6667 - val_loss: 0.6820\n",
      "Epoch 64/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6350 - val_loss: 0.4985\n",
      "Epoch 65/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6117 - val_loss: 0.5461\n",
      "Epoch 66/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6159 - val_loss: 0.5049\n",
      "Epoch 67/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6560 - val_loss: 0.5519\n",
      "Epoch 68/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6000 - val_loss: 0.4789\n",
      "Epoch 69/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6235 - val_loss: 0.6555\n",
      "Epoch 70/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6044 - val_loss: 0.6944\n",
      "Epoch 71/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6268 - val_loss: 0.6314\n",
      "Epoch 72/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6082 - val_loss: 0.7271\n",
      "Epoch 73/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6210 - val_loss: 0.6072\n",
      "Epoch 74/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6143 - val_loss: 0.6139\n",
      "Epoch 75/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6063 - val_loss: 0.7116\n",
      "Epoch 76/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6109 - val_loss: 0.6407\n",
      "Epoch 77/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5677 - val_loss: 0.4306\n",
      "Epoch 78/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5777 - val_loss: 0.5092\n",
      "Epoch 79/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5810 - val_loss: 0.5192\n",
      "Epoch 80/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5880 - val_loss: 0.5457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5994 - val_loss: 0.8081\n",
      "Epoch 82/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6154 - val_loss: 0.6907\n",
      "Epoch 83/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5673 - val_loss: 0.7798\n",
      "Epoch 84/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5763 - val_loss: 0.6135\n",
      "Epoch 85/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5435 - val_loss: 0.6164\n",
      "Epoch 86/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5460 - val_loss: 0.7147\n",
      "Epoch 87/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5280 - val_loss: 0.6171\n",
      "Epoch 88/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5769 - val_loss: 0.7895\n",
      "Epoch 89/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5022 - val_loss: 0.7961\n",
      "Epoch 90/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5096 - val_loss: 0.8056\n",
      "Epoch 91/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5380 - val_loss: 0.8224\n",
      "Epoch 92/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4826 - val_loss: 0.5599\n",
      "Epoch 93/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5014 - val_loss: 0.5875\n",
      "Epoch 94/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5205 - val_loss: 0.5691\n",
      "Epoch 95/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5725 - val_loss: 0.6031\n",
      "Epoch 96/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5069 - val_loss: 0.6841\n",
      "Epoch 97/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4966 - val_loss: 0.8197\n",
      "Epoch 98/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5282 - val_loss: 0.8957\n",
      "Epoch 99/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.5168 - val_loss: 0.5527\n",
      "Epoch 100/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.5270 - val_loss: 0.9491\n",
      "Epoch 101/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4836 - val_loss: 0.6038\n",
      "Epoch 102/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4618 - val_loss: 0.6630\n",
      "Epoch 103/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4950 - val_loss: 0.8112\n",
      "Epoch 104/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4966 - val_loss: 0.8306\n",
      "Epoch 105/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5064 - val_loss: 0.7267\n",
      "Epoch 106/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4508 - val_loss: 0.9999\n",
      "Epoch 107/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4596 - val_loss: 1.0045\n",
      "Epoch 108/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4742 - val_loss: 1.1916\n",
      "Epoch 109/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5193 - val_loss: 0.6760\n",
      "Epoch 110/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4793 - val_loss: 0.7640\n",
      "Epoch 111/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4395 - val_loss: 0.8116\n",
      "Epoch 112/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4865 - val_loss: 0.7557\n",
      "Epoch 113/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4961 - val_loss: 0.9213\n",
      "Epoch 114/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5094 - val_loss: 0.7591\n",
      "Epoch 115/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4687 - val_loss: 0.9091\n",
      "Epoch 116/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4388 - val_loss: 0.9004\n",
      "Epoch 117/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4542 - val_loss: 0.6977\n",
      "Epoch 118/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4544 - val_loss: 0.7041\n",
      "Epoch 119/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4483 - val_loss: 0.6655\n",
      "Epoch 120/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4482 - val_loss: 0.6184\n",
      "Epoch 121/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4929 - val_loss: 0.6169\n",
      "Epoch 122/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4867 - val_loss: 0.9176\n",
      "Epoch 123/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5118 - val_loss: 0.7562\n",
      "Epoch 124/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4461 - val_loss: 0.6076\n",
      "Epoch 125/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4356 - val_loss: 0.5983\n",
      "Epoch 126/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4688 - val_loss: 0.6862\n",
      "Epoch 127/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4565 - val_loss: 0.7434\n",
      "Epoch 128/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4457 - val_loss: 0.9075\n",
      "Epoch 129/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4992 - val_loss: 0.7430\n",
      "Epoch 130/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4595 - val_loss: 1.2680\n",
      "Epoch 131/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4597 - val_loss: 0.6574\n",
      "Epoch 132/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4173 - val_loss: 0.7273\n",
      "Epoch 133/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4337 - val_loss: 0.7831\n",
      "Epoch 134/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4648 - val_loss: 0.5997\n",
      "Epoch 135/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4881 - val_loss: 0.4979\n",
      "Epoch 136/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4130 - val_loss: 0.9040\n",
      "Epoch 137/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4306 - val_loss: 0.6399\n",
      "Epoch 138/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4368 - val_loss: 0.6516\n",
      "Epoch 139/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3927 - val_loss: 0.6040\n",
      "Epoch 140/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4108 - val_loss: 0.7863\n",
      "Epoch 141/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4696 - val_loss: 1.0038\n",
      "Epoch 142/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3986 - val_loss: 0.5385\n",
      "Epoch 143/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4150 - val_loss: 0.6771\n",
      "Epoch 144/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4345 - val_loss: 1.0157\n",
      "Epoch 145/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4177 - val_loss: 0.7768\n",
      "Epoch 146/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3941 - val_loss: 0.6513\n",
      "Epoch 147/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4420 - val_loss: 0.8292\n",
      "Epoch 148/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4160 - val_loss: 0.6096\n",
      "Epoch 149/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3914 - val_loss: 0.7027\n",
      "Epoch 150/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4061 - val_loss: 0.9026\n",
      "Epoch 151/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3870 - val_loss: 1.0229\n",
      "Epoch 152/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3880 - val_loss: 0.8419\n",
      "Epoch 153/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4530 - val_loss: 1.0713\n",
      "Epoch 154/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3810 - val_loss: 0.6530\n",
      "Epoch 155/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4790 - val_loss: 0.6621\n",
      "Epoch 156/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4137 - val_loss: 1.0123\n",
      "Epoch 157/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4126 - val_loss: 0.9391\n",
      "Epoch 158/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3967 - val_loss: 0.6681\n",
      "Epoch 159/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4162 - val_loss: 0.8675\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4703 - val_loss: 0.7238\n",
      "Epoch 161/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4734 - val_loss: 0.7388\n",
      "Epoch 162/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4363 - val_loss: 1.0396\n",
      "Epoch 163/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4348 - val_loss: 0.7510\n",
      "Epoch 164/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3901 - val_loss: 0.7476\n",
      "Epoch 165/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3982 - val_loss: 0.9889\n",
      "Epoch 166/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4609 - val_loss: 0.6628\n",
      "Epoch 167/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3995 - val_loss: 0.8141\n",
      "Epoch 168/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3990 - val_loss: 0.7665\n",
      "Epoch 169/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4062 - val_loss: 0.7377\n",
      "Epoch 170/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3753 - val_loss: 0.8158\n",
      "Epoch 171/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3806 - val_loss: 1.0258\n",
      "Epoch 172/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3853 - val_loss: 0.9674\n",
      "Epoch 173/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4025 - val_loss: 0.8019\n",
      "Epoch 174/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3866 - val_loss: 0.6434\n",
      "Epoch 175/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4144 - val_loss: 0.7629\n",
      "Epoch 176/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4088 - val_loss: 0.6338\n",
      "Epoch 177/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3925 - val_loss: 1.0134\n",
      "Epoch 178/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4217 - val_loss: 1.0506\n",
      "Epoch 179/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4461 - val_loss: 0.5631\n",
      "Epoch 180/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4275 - val_loss: 0.9123\n",
      "Epoch 181/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3812 - val_loss: 1.3763\n",
      "Epoch 182/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3797 - val_loss: 0.6617\n",
      "Epoch 183/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4165 - val_loss: 0.8856\n",
      "Epoch 184/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4112 - val_loss: 1.0511\n",
      "Epoch 185/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4468 - val_loss: 1.1581\n",
      "Epoch 186/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3625 - val_loss: 0.9896\n",
      "Epoch 187/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3920 - val_loss: 1.0440\n",
      "Epoch 188/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4033 - val_loss: 1.0192\n",
      "Epoch 189/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3760 - val_loss: 0.7007\n",
      "Epoch 190/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3606 - val_loss: 1.1776\n",
      "Epoch 191/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4105 - val_loss: 1.1350\n",
      "Epoch 192/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4103 - val_loss: 0.8928\n",
      "Epoch 193/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4093 - val_loss: 0.9823\n",
      "Epoch 194/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3521 - val_loss: 1.0762\n",
      "Epoch 195/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.3806 - val_loss: 0.6385\n",
      "Epoch 196/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4045 - val_loss: 1.0156\n",
      "Epoch 197/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3924 - val_loss: 1.0220\n",
      "Epoch 198/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4048 - val_loss: 1.4667\n",
      "Epoch 199/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3931 - val_loss: 0.9316\n",
      "Epoch 200/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4291 - val_loss: 1.0615\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_6 (Bidirection (None, 24, 12)            684       \n",
      "_________________________________________________________________\n",
      "layer_normalization_5 (Layer (None, 24, 12)            24        \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 12)                684       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,405\n",
      "Trainable params: 1,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Saved\n",
      "Predict time:  0.4306211471557617\n",
      "RMSE:  4.178591181750636\n",
      "RMSE2:  1.688568509021198\n",
      "MAE:  3.3788501540819804\n",
      "MAE2:  3.3788501540819804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse score')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "init = glorot_normal(seed=None) # 給 LSTM\n",
    "init_d = RandomUniform(minval=-0.05, maxval=0.05) # 給 Dense layer\n",
    "nadam = optimizers.Nadam(lr=0.0015,clipvalue=0.5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(6, kernel_initializer=init ,return_sequences = True,kernel_regularizer=regularizers.l2(0.01)\n",
    "                             ,recurrent_regularizer = regularizers.l2(0.01) ,input_shape=(x_train.shape[1],x_train.shape[2]))))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Bidirectional(GRU(6,kernel_initializer=init,kernel_regularizer=regularizers.l2(0.01),recurrent_regularizer = regularizers.l2(0.01))))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1, kernel_initializer=init_d))\n",
    "model.compile(optimizer = nadam , loss=\"mse\")\n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size=24, validation_split=0.1, shuffle=True)\n",
    "#model summary\n",
    "model.summary()\n",
    "#Save Model\n",
    "model.save('GRU_model_South.h5')  # creates a HDF5 file \n",
    "print('Model Saved')\n",
    "del model  # deletes the existing model\n",
    "\n",
    "custom_ob = {'LayerNormalization': LayerNormalization , 'SeqSelfAttention':SeqSelfAttention}\n",
    "model = load_model('GRU_model_South.h5', custom_objects=custom_ob)\n",
    "t1 = time.time()\n",
    "# y_pred = model.predict([x_test,x_test])\n",
    "y_pred2 = model.predict(x_test)\n",
    "y_pred = model.predict(x_train)\n",
    "t2 = time.time()\n",
    "print('Predict time: ',t2-t1)\n",
    "y_pred = scaler.inverse_transform(y_pred)#Undo scaling\n",
    "rmse_lstm2 = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print('RMSE: ',rmse_lstm)\n",
    "print('RMSE2: ',rmse_lstm2)\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('MAE: ',mae)\n",
    "print('MAE2: ',mae)\n",
    "# r22 =  r2_score(y_test, y_pred2)\n",
    "# r2 =  r2_score(y_train, y_pred)\n",
    "# print('R-square: ',r2)\n",
    "# print('R-square2: ',r22)\n",
    "\n",
    "# n = len(y_test)\n",
    "# p = 12\n",
    "# Adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "# Adj_r22 = 1-(1-r22)*(n-1)/(n-p-1)\n",
    "# print('Adj R-square: ',Adj_r2)\n",
    "# print('Adj R-square2: ',Adj_r22)\n",
    "\n",
    "plt.plot(history.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"No. Of Epochs\")\n",
    "plt.ylabel(\"mse score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee13da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac0ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
