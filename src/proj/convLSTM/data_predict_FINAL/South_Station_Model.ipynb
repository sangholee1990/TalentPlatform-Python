{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cca7b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tcn import TCN\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential , load_model , Model\n",
    "from keras.layers import Dense, Dropout , LSTM , Bidirectional ,GRU ,Flatten,Add,BatchNormalization\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras.initializers import  glorot_normal, RandomUniform\n",
    "from keras import optimizers,Input\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80213eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 13) (144, 13) (40, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7983f645c144d0b929781bbed77e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677e777e7553497c9dfde22e1e0af541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:\n",
      "(120, 24, 12) (120,)\n",
      "Test size:\n",
      "(16, 24, 12) (16,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"station_bike _South.csv\")\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df = df.set_index(\"timestamp\")\n",
    "#df.head()\n",
    "\n",
    "df[\"hour\"] = df.index.hour\n",
    "df[\"day_of_month\"] = df.index.day\n",
    "df[\"day_of_week\"]  = df.index.dayofweek\n",
    "df[\"month\"] = df.index.month\n",
    "\n",
    "training_data_len = math.ceil(len(df) * 0.9) # taking 90% of data to train and 10% of data to test\n",
    "testing_data_len = len(df) - training_data_len\n",
    "\n",
    "time_steps = 24\n",
    "train, test = df.iloc[0:training_data_len], df.iloc[(training_data_len-time_steps):len(df)]\n",
    "print(df.shape, train.shape, test.shape)\n",
    "train_trans = train[['t1','t2', 'hum', 'wind_speed']].to_numpy()\n",
    "test_trans = test[['t1','t2', 'hum', 'wind_speed']].to_numpy()\n",
    "\n",
    "scaler = RobustScaler() # Handles outliers\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1)) # scale to (0,1)\n",
    "train.loc[:, ['t1','t2','hum', 'wind_speed']]=scaler.fit_transform(train_trans)\n",
    "test.loc[:, ['t1','t2', 'hum', 'wind_speed']]=scaler.fit_transform(test_trans)\n",
    "\n",
    "train['cnt'] = scaler.fit_transform(train[['cnt']])\n",
    "test['cnt'] = scaler.fit_transform(test[['cnt']])\n",
    "\n",
    "#Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in tqdm(range(len(train) - time_steps)):\n",
    "    x_train.append(train.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n",
    "    y_train.append(train.loc[:,'cnt'].iloc[i + time_steps])\n",
    "\n",
    "#Convert x_train and y_train to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "#Create the x_test and y_test data sets\n",
    "x_test = []\n",
    "y_test = df.loc[:,'cnt'].iloc[training_data_len:len(df)]\n",
    "\n",
    "for i in tqdm(range(len(test) - time_steps)):\n",
    "    x_test.append(test.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n",
    "    # y_test.append(test.loc[:,'cnt'].iloc[i + time_steps])\n",
    "\n",
    "#Convert x_test and y_test to numpy arrays\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# All 12 columns of the data\n",
    "print('Train size:')\n",
    "print(x_train.shape, y_train.shape)\n",
    "print('Test size:')\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b616f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 24, 12)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 24)       1800        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_3 (SeqSelfAt (None, 24, 24)       577         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 24)       0           seq_self_attention_3[0][0]       \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 24, 24)       48          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           6924        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 588)          0           dropout_3[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            589         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,940\n",
      "Trainable params: 9,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "init = glorot_normal(seed=None) # 給 GRU\n",
    "init_d = RandomUniform(minval=-0.05, maxval=0.05) # 給 Dense layer\n",
    "\n",
    "def Encoder(layer):\n",
    "    shortcut = layer\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = Add()([layer,shortcut])\n",
    "    layer = LayerNormalization()(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    \n",
    "    shortcut2 = layer\n",
    "    layer = Dense(12,kernel_initializer=init_d)(layer)\n",
    "    layer = Dropout(0.15)(layer)\n",
    "    layer = Concatenate()([layer,shortcut2])\n",
    "    output = Dense(1,kernel_initializer=init_d)(layer)\n",
    "    return output\n",
    "\n",
    "def Decoder(layer):\n",
    "    shortcut = layer\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = Add()([layer,shortcut])\n",
    "    layer = LayerNormalization()(layer)\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = LayerNormalization()(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    shortcut2 = layer\n",
    "    layer = Dense(10,kernel_initializer=init_d)(layer)\n",
    "    #layer = Dropout(0.2)(layer)\n",
    "    layer = Concatenate()([layer,shortcut2])\n",
    "    output = Dense(1,kernel_initializer=init_d)(layer)\n",
    "    return output\n",
    "\n",
    "def Bi_GRU(layer,unit):\n",
    "    output = Bidirectional(GRU(unit, dropout=0.1, recurrent_dropout=0.1, return_sequences=True,\n",
    "                            kernel_initializer=init))(layer)\n",
    "    return output\n",
    "\n",
    "#start = Input(shape = (x_train.shape[1],x_train.shape[2]))\n",
    "start = Input(shape = (x_train.shape[1:]))\n",
    "start2 = Input(shape = (x_train.shape[1:]))\n",
    "x = Bi_GRU(start,12)\n",
    "x = Encoder(x)\n",
    "\n",
    "# y = Bi_GRU(start2,8)\n",
    "# y = Decoder(y)\n",
    "\n",
    "#Merge = Add()([x,x])\n",
    "Last = Dense(1)(x)\n",
    "model = Model([start,start2] , Last)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66191abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 1.6046 - val_loss: 0.7048\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.4167 - val_loss: 0.6647\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0875 - val_loss: 0.5437\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0925 - val_loss: 0.7220\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.2357 - val_loss: 0.4956\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0683 - val_loss: 0.5037\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9219 - val_loss: 0.3669\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9123 - val_loss: 0.3657\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7869 - val_loss: 0.3537\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7933 - val_loss: 0.3980\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7366 - val_loss: 0.3975\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7425 - val_loss: 0.3710\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7393 - val_loss: 0.3667\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7122 - val_loss: 0.6965\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7857 - val_loss: 0.3694\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6994 - val_loss: 0.3775\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6583 - val_loss: 0.3998\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7880 - val_loss: 0.3645\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6021 - val_loss: 0.4418\n",
      "Epoch 20/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6077 - val_loss: 0.3561\n",
      "Epoch 21/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5231 - val_loss: 0.3569\n",
      "Epoch 22/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5813 - val_loss: 0.5404\n",
      "Epoch 23/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6103 - val_loss: 0.5825\n",
      "Epoch 24/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5765 - val_loss: 0.3405\n",
      "Epoch 25/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5836 - val_loss: 0.3276\n",
      "Epoch 26/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5522 - val_loss: 0.3114\n",
      "Epoch 27/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6340 - val_loss: 0.3459\n",
      "Epoch 28/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5011 - val_loss: 0.3498\n",
      "Epoch 29/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4852 - val_loss: 0.3446\n",
      "Epoch 30/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4698 - val_loss: 0.6661\n",
      "Epoch 31/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6206 - val_loss: 0.3837\n",
      "Epoch 32/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5078 - val_loss: 0.4048\n",
      "Epoch 33/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5087 - val_loss: 0.2949\n",
      "Epoch 34/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6164 - val_loss: 0.2910\n",
      "Epoch 35/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5096 - val_loss: 0.2646\n",
      "Epoch 36/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5690 - val_loss: 0.2660\n",
      "Epoch 37/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4596 - val_loss: 0.3404\n",
      "Epoch 38/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5417 - val_loss: 0.3827\n",
      "Epoch 39/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4431 - val_loss: 0.3353\n",
      "Epoch 40/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3912 - val_loss: 0.5615\n",
      "Epoch 41/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5452 - val_loss: 0.5832\n",
      "Epoch 42/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5643 - val_loss: 0.3098\n",
      "Epoch 43/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3467 - val_loss: 0.3399\n",
      "Epoch 44/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4724 - val_loss: 0.3557\n",
      "Epoch 45/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.5266 - val_loss: 0.7763\n",
      "Epoch 46/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3821 - val_loss: 0.4879\n",
      "Epoch 47/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4147 - val_loss: 0.5099\n",
      "Epoch 48/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4490 - val_loss: 0.6780\n",
      "Epoch 49/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4174 - val_loss: 0.4100\n",
      "Epoch 50/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.3155 - val_loss: 0.3439\n",
      "Epoch 51/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3392 - val_loss: 0.2802\n",
      "Epoch 52/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3328 - val_loss: 0.3030\n",
      "Epoch 53/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3726 - val_loss: 0.3936\n",
      "Epoch 54/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3975 - val_loss: 0.2804\n",
      "Epoch 55/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3338 - val_loss: 0.4370\n",
      "Epoch 56/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3399 - val_loss: 0.3102\n",
      "Epoch 57/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3555 - val_loss: 0.3589\n",
      "Epoch 58/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3072 - val_loss: 0.6175\n",
      "Epoch 59/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3377 - val_loss: 0.3128\n",
      "Epoch 60/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3974 - val_loss: 0.5247\n",
      "Epoch 61/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3296 - val_loss: 0.6169\n",
      "Epoch 62/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2637 - val_loss: 0.3206\n",
      "Epoch 63/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4285 - val_loss: 0.2798\n",
      "Epoch 64/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3390 - val_loss: 0.2654\n",
      "Epoch 65/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3449 - val_loss: 0.2873\n",
      "Epoch 66/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3561 - val_loss: 0.3470\n",
      "Epoch 67/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2938 - val_loss: 0.2750\n",
      "Epoch 68/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3106 - val_loss: 0.2985\n",
      "Epoch 69/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3041 - val_loss: 0.4321\n",
      "Epoch 70/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3789 - val_loss: 0.3482\n",
      "Epoch 71/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3032 - val_loss: 0.4522\n",
      "Epoch 72/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3640 - val_loss: 0.3124\n",
      "Epoch 73/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3129 - val_loss: 0.3023\n",
      "Epoch 74/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2949 - val_loss: 0.3756\n",
      "Epoch 75/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3685 - val_loss: 0.1985\n",
      "Epoch 76/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3889 - val_loss: 0.9581\n",
      "Epoch 77/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4260 - val_loss: 0.9440\n",
      "Epoch 78/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3438 - val_loss: 0.4674\n",
      "Epoch 79/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2603 - val_loss: 0.1987\n",
      "Epoch 80/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3255 - val_loss: 0.1743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.4199 - val_loss: 0.2039\n",
      "Epoch 82/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2386 - val_loss: 0.2937\n",
      "Epoch 83/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3458 - val_loss: 0.2961\n",
      "Epoch 84/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3434 - val_loss: 0.1751\n",
      "Epoch 85/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2553 - val_loss: 0.2276\n",
      "Epoch 86/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2857 - val_loss: 0.2640\n",
      "Epoch 87/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2956 - val_loss: 0.2192\n",
      "Epoch 88/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3428 - val_loss: 0.6106\n",
      "Epoch 89/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2644 - val_loss: 0.2452\n",
      "Epoch 90/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2662 - val_loss: 0.5012\n",
      "Epoch 91/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2541 - val_loss: 0.2661\n",
      "Epoch 92/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2423 - val_loss: 0.2656\n",
      "Epoch 93/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2990 - val_loss: 0.4578\n",
      "Epoch 94/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2349 - val_loss: 0.3175\n",
      "Epoch 95/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2756 - val_loss: 0.3220\n",
      "Epoch 96/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.2966 - val_loss: 0.4140\n",
      "Epoch 97/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3088 - val_loss: 0.1797\n",
      "Epoch 98/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3963 - val_loss: 0.2247\n",
      "Epoch 99/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3355 - val_loss: 0.3139\n",
      "Epoch 100/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2166 - val_loss: 0.1978\n",
      "Epoch 101/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2598 - val_loss: 0.1971\n",
      "Epoch 102/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2544 - val_loss: 0.2774\n",
      "Epoch 103/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2216 - val_loss: 0.1912\n",
      "Epoch 104/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1903 - val_loss: 0.1875\n",
      "Epoch 105/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2578 - val_loss: 0.2596\n",
      "Epoch 106/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3167 - val_loss: 0.2751\n",
      "Epoch 107/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2194 - val_loss: 0.1749\n",
      "Epoch 108/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2289 - val_loss: 0.1639\n",
      "Epoch 109/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1900 - val_loss: 0.2245\n",
      "Epoch 110/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2417 - val_loss: 0.1793\n",
      "Epoch 111/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2234 - val_loss: 0.2307\n",
      "Epoch 112/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2482 - val_loss: 0.1813\n",
      "Epoch 113/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2311 - val_loss: 0.4087\n",
      "Epoch 114/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.3590 - val_loss: 0.2814\n",
      "Epoch 115/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2567 - val_loss: 0.4519\n",
      "Epoch 116/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2184 - val_loss: 0.2139\n",
      "Epoch 117/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1958 - val_loss: 0.1444\n",
      "Epoch 118/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2294 - val_loss: 0.1762\n",
      "Epoch 119/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2110 - val_loss: 0.1741\n",
      "Epoch 120/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2122 - val_loss: 0.2546\n",
      "Epoch 121/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2389 - val_loss: 0.2361\n",
      "Epoch 122/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2116 - val_loss: 0.1788\n",
      "Epoch 123/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2107 - val_loss: 0.3451\n",
      "Epoch 124/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1935 - val_loss: 0.3296\n",
      "Epoch 125/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2778 - val_loss: 0.2465\n",
      "Epoch 126/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2737 - val_loss: 0.1326\n",
      "Epoch 127/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2134 - val_loss: 0.2333\n",
      "Epoch 128/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1878 - val_loss: 0.1480\n",
      "Epoch 129/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1866 - val_loss: 0.2288\n",
      "Epoch 130/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1723 - val_loss: 0.3070\n",
      "Epoch 131/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2067 - val_loss: 0.1770\n",
      "Epoch 132/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1724 - val_loss: 0.2622\n",
      "Epoch 133/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1689 - val_loss: 0.1860\n",
      "Epoch 134/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1960 - val_loss: 0.2406\n",
      "Epoch 135/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2308 - val_loss: 0.3005\n",
      "Epoch 136/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2533 - val_loss: 0.3146\n",
      "Epoch 137/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2360 - val_loss: 0.2084\n",
      "Epoch 138/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2092 - val_loss: 0.2847\n",
      "Epoch 139/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1981 - val_loss: 0.2322\n",
      "Epoch 140/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2853 - val_loss: 0.1790\n",
      "Epoch 141/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1856 - val_loss: 0.2447\n",
      "Epoch 142/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2233 - val_loss: 0.2634\n",
      "Epoch 143/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1666 - val_loss: 0.2192\n",
      "Epoch 144/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1733 - val_loss: 0.3564\n",
      "Epoch 145/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1642 - val_loss: 0.2331\n",
      "Epoch 146/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1866 - val_loss: 0.1517\n",
      "Epoch 147/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2030 - val_loss: 0.2837\n",
      "Epoch 148/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1585 - val_loss: 0.1953\n",
      "Epoch 149/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1945 - val_loss: 0.2402\n",
      "Epoch 150/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2412 - val_loss: 0.3506\n",
      "Epoch 151/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1517 - val_loss: 0.2793\n",
      "Epoch 152/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1998 - val_loss: 0.2590\n",
      "Epoch 153/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1497 - val_loss: 0.4020\n",
      "Epoch 154/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1658 - val_loss: 0.2182\n",
      "Epoch 155/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2074 - val_loss: 0.1992\n",
      "Epoch 156/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2262 - val_loss: 0.2378\n",
      "Epoch 157/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1552 - val_loss: 0.1633\n",
      "Epoch 158/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2007 - val_loss: 0.2602\n",
      "Epoch 159/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1834 - val_loss: 0.3352\n",
      "Epoch 160/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1819 - val_loss: 0.1533\n",
      "Epoch 161/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2320 - val_loss: 0.2062\n",
      "Epoch 162/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2044 - val_loss: 0.1543\n",
      "Epoch 163/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1939 - val_loss: 0.4192\n",
      "Epoch 164/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1838 - val_loss: 0.4897\n",
      "Epoch 165/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2852 - val_loss: 0.1790\n",
      "Epoch 166/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1597 - val_loss: 0.3495\n",
      "Epoch 167/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1459 - val_loss: 0.4531\n",
      "Epoch 168/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2082 - val_loss: 0.2456\n",
      "Epoch 169/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2074 - val_loss: 0.1201\n",
      "Epoch 170/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2381 - val_loss: 0.1317\n",
      "Epoch 171/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1987 - val_loss: 0.2461\n",
      "Epoch 172/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2144 - val_loss: 0.4818\n",
      "Epoch 173/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2114 - val_loss: 0.3363\n",
      "Epoch 174/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2128 - val_loss: 0.3736\n",
      "Epoch 175/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1850 - val_loss: 0.2621\n",
      "Epoch 176/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1722 - val_loss: 0.1925\n",
      "Epoch 177/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1849 - val_loss: 0.1365\n",
      "Epoch 178/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1559 - val_loss: 0.2278\n",
      "Epoch 179/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2865 - val_loss: 0.2126\n",
      "Epoch 180/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1879 - val_loss: 0.2853\n",
      "Epoch 181/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1607 - val_loss: 0.2967\n",
      "Epoch 182/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1376 - val_loss: 0.2970\n",
      "Epoch 183/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1437 - val_loss: 0.1472\n",
      "Epoch 184/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1702 - val_loss: 0.2834\n",
      "Epoch 185/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1921 - val_loss: 0.1829\n",
      "Epoch 186/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1639 - val_loss: 0.1345\n",
      "Epoch 187/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1850 - val_loss: 0.2755\n",
      "Epoch 188/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1416 - val_loss: 0.1836\n",
      "Epoch 189/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2123 - val_loss: 0.1497\n",
      "Epoch 190/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1525 - val_loss: 0.1693\n",
      "Epoch 191/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1655 - val_loss: 0.1660\n",
      "Epoch 192/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1362 - val_loss: 0.2351\n",
      "Epoch 193/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1800 - val_loss: 0.1374\n",
      "Epoch 194/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2233 - val_loss: 0.2119\n",
      "Epoch 195/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1916 - val_loss: 0.2037\n",
      "Epoch 196/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1321 - val_loss: 0.1644\n",
      "Epoch 197/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2377 - val_loss: 0.2757\n",
      "Epoch 198/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2180 - val_loss: 0.1992\n",
      "Epoch 199/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1488 - val_loss: 0.4565\n",
      "Epoch 200/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1750 - val_loss: 0.4339\n",
      "Epoch 201/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1978 - val_loss: 0.2105\n",
      "Epoch 202/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1320 - val_loss: 0.2496\n",
      "Epoch 203/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1237 - val_loss: 0.2106\n",
      "Epoch 204/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1596 - val_loss: 0.1535\n",
      "Epoch 205/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1338 - val_loss: 0.2842\n",
      "Epoch 206/500\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.106 - 1s 7ms/step - loss: 0.1046 - val_loss: 0.3452\n",
      "Epoch 207/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1791 - val_loss: 0.1439\n",
      "Epoch 208/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1544 - val_loss: 0.2444\n",
      "Epoch 209/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1965 - val_loss: 0.5347\n",
      "Epoch 210/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1969 - val_loss: 0.2967\n",
      "Epoch 211/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1032 - val_loss: 0.1822\n",
      "Epoch 212/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1368 - val_loss: 0.2287\n",
      "Epoch 213/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1341 - val_loss: 0.3209\n",
      "Epoch 214/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1471 - val_loss: 0.1957\n",
      "Epoch 215/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1473 - val_loss: 0.2114\n",
      "Epoch 216/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1014 - val_loss: 0.1998\n",
      "Epoch 217/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1374 - val_loss: 0.2918\n",
      "Epoch 218/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1331 - val_loss: 0.1522\n",
      "Epoch 219/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1677 - val_loss: 0.1278\n",
      "Epoch 220/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1882 - val_loss: 0.2526\n",
      "Epoch 221/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1653 - val_loss: 0.1791\n",
      "Epoch 222/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1809 - val_loss: 0.3198\n",
      "Epoch 223/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2191 - val_loss: 0.3059\n",
      "Epoch 224/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1454 - val_loss: 0.3136\n",
      "Epoch 225/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1484 - val_loss: 0.2828\n",
      "Epoch 226/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1304 - val_loss: 0.1476\n",
      "Epoch 227/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1163 - val_loss: 0.1994\n",
      "Epoch 228/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2259 - val_loss: 0.1767\n",
      "Epoch 229/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1975 - val_loss: 0.3297\n",
      "Epoch 230/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1480 - val_loss: 0.4005\n",
      "Epoch 231/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2098 - val_loss: 0.2020\n",
      "Epoch 232/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1190 - val_loss: 0.3957\n",
      "Epoch 233/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1268 - val_loss: 0.3309\n",
      "Epoch 234/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1271 - val_loss: 0.1669\n",
      "Epoch 235/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0995 - val_loss: 0.2613\n",
      "Epoch 236/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1852 - val_loss: 0.1380\n",
      "Epoch 237/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1118 - val_loss: 0.2429\n",
      "Epoch 238/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1163 - val_loss: 0.2269\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1078 - val_loss: 0.2328\n",
      "Epoch 240/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1170 - val_loss: 0.3323\n",
      "Epoch 241/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1283 - val_loss: 0.1713\n",
      "Epoch 242/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1079 - val_loss: 0.3249\n",
      "Epoch 243/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1065 - val_loss: 0.3606\n",
      "Epoch 244/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1725 - val_loss: 0.1893\n",
      "Epoch 245/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1364 - val_loss: 0.5748\n",
      "Epoch 246/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1699 - val_loss: 0.1791\n",
      "Epoch 247/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1008 - val_loss: 0.2347\n",
      "Epoch 248/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1324 - val_loss: 0.4378\n",
      "Epoch 249/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1626 - val_loss: 0.2676\n",
      "Epoch 250/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1394 - val_loss: 0.1652\n",
      "Epoch 251/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1347 - val_loss: 0.2570\n",
      "Epoch 252/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1208 - val_loss: 0.2380\n",
      "Epoch 253/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1673 - val_loss: 0.3129\n",
      "Epoch 254/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1078 - val_loss: 0.1737\n",
      "Epoch 255/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1108 - val_loss: 0.2565\n",
      "Epoch 256/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1324 - val_loss: 0.2061\n",
      "Epoch 257/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1042 - val_loss: 0.3277\n",
      "Epoch 258/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1118 - val_loss: 0.2420\n",
      "Epoch 259/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1007 - val_loss: 0.3420\n",
      "Epoch 260/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1004 - val_loss: 0.2037\n",
      "Epoch 261/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0853 - val_loss: 0.1621\n",
      "Epoch 262/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0993 - val_loss: 0.1590\n",
      "Epoch 263/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1125 - val_loss: 0.2109\n",
      "Epoch 264/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1372 - val_loss: 0.2453\n",
      "Epoch 265/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1150 - val_loss: 0.4636\n",
      "Epoch 266/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1393 - val_loss: 0.4182\n",
      "Epoch 267/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0996 - val_loss: 0.2235\n",
      "Epoch 268/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0911 - val_loss: 0.2524\n",
      "Epoch 269/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1223 - val_loss: 0.1356\n",
      "Epoch 270/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1497 - val_loss: 0.2409\n",
      "Epoch 271/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2026 - val_loss: 1.2142\n",
      "Epoch 272/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1641 - val_loss: 0.3835\n",
      "Epoch 273/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1190 - val_loss: 0.1615\n",
      "Epoch 274/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0999 - val_loss: 0.2530\n",
      "Epoch 275/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1306 - val_loss: 0.1961\n",
      "Epoch 276/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1235 - val_loss: 0.1682\n",
      "Epoch 277/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1293 - val_loss: 0.2644\n",
      "Epoch 278/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1028 - val_loss: 0.3484\n",
      "Epoch 279/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1169 - val_loss: 0.5012\n",
      "Epoch 280/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1741 - val_loss: 0.2784\n",
      "Epoch 281/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1727 - val_loss: 0.1893\n",
      "Epoch 282/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.1298 - val_loss: 0.1436\n",
      "Epoch 283/500\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.106 - 1s 7ms/step - loss: 0.1106 - val_loss: 0.2854\n",
      "Epoch 284/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0943 - val_loss: 0.2462\n",
      "Epoch 285/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1060 - val_loss: 0.2090\n",
      "Epoch 286/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0785 - val_loss: 0.2653\n",
      "Epoch 287/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1014 - val_loss: 0.2275\n",
      "Epoch 288/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0878 - val_loss: 0.1437\n",
      "Epoch 289/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1359 - val_loss: 0.1745\n",
      "Epoch 290/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1236 - val_loss: 0.2984\n",
      "Epoch 291/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1342 - val_loss: 0.1684\n",
      "Epoch 292/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1106 - val_loss: 0.1193\n",
      "Epoch 293/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0997 - val_loss: 0.2104\n",
      "Epoch 294/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0752 - val_loss: 0.1970\n",
      "Epoch 295/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0829 - val_loss: 0.2532\n",
      "Epoch 296/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0878 - val_loss: 0.1498\n",
      "Epoch 297/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0817 - val_loss: 0.1355\n",
      "Epoch 298/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1288 - val_loss: 0.1319\n",
      "Epoch 299/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1060 - val_loss: 0.4014\n",
      "Epoch 300/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0848 - val_loss: 0.1792\n",
      "Epoch 301/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1196 - val_loss: 0.1100\n",
      "Epoch 302/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0989 - val_loss: 0.1974\n",
      "Epoch 303/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1448 - val_loss: 0.2957\n",
      "Epoch 304/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0984 - val_loss: 0.1523\n",
      "Epoch 305/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1301 - val_loss: 0.4448\n",
      "Epoch 306/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0700 - val_loss: 0.3923\n",
      "Epoch 307/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1169 - val_loss: 0.3198\n",
      "Epoch 308/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0945 - val_loss: 0.2626\n",
      "Epoch 309/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0954 - val_loss: 0.2481\n",
      "Epoch 310/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0940 - val_loss: 0.2261\n",
      "Epoch 311/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1307 - val_loss: 0.2186\n",
      "Epoch 312/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0798 - val_loss: 0.1717\n",
      "Epoch 313/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0744 - val_loss: 0.1482\n",
      "Epoch 314/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1425 - val_loss: 0.1748\n",
      "Epoch 315/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1036 - val_loss: 0.2001\n",
      "Epoch 316/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0969 - val_loss: 0.3562\n",
      "Epoch 317/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0918 - val_loss: 0.1490\n",
      "Epoch 318/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1133 - val_loss: 0.1653\n",
      "Epoch 319/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0848 - val_loss: 0.2547\n",
      "Epoch 320/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0677 - val_loss: 0.1730\n",
      "Epoch 321/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0655 - val_loss: 0.2422\n",
      "Epoch 322/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0856 - val_loss: 0.2586\n",
      "Epoch 323/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0750 - val_loss: 0.1572\n",
      "Epoch 324/500\n",
      "108/108 [==============================] - 1s 8ms/step - loss: 0.0690 - val_loss: 0.1649\n",
      "Epoch 325/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1112 - val_loss: 0.2257\n",
      "Epoch 326/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0760 - val_loss: 0.2516\n",
      "Epoch 327/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0810 - val_loss: 0.2464\n",
      "Epoch 328/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0922 - val_loss: 0.3531\n",
      "Epoch 329/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0719 - val_loss: 0.2432\n",
      "Epoch 330/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1680 - val_loss: 0.2705\n",
      "Epoch 331/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1149 - val_loss: 0.5313\n",
      "Epoch 332/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1323 - val_loss: 0.4417\n",
      "Epoch 333/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1306 - val_loss: 0.2889\n",
      "Epoch 334/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0794 - val_loss: 0.2113\n",
      "Epoch 335/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1119 - val_loss: 0.1549\n",
      "Epoch 336/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1144 - val_loss: 0.1503\n",
      "Epoch 337/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0677 - val_loss: 0.2193\n",
      "Epoch 338/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0969 - val_loss: 0.2427\n",
      "Epoch 339/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.3073\n",
      "Epoch 340/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0845 - val_loss: 0.3480\n",
      "Epoch 341/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0894 - val_loss: 0.1655\n",
      "Epoch 342/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0670 - val_loss: 0.2292\n",
      "Epoch 343/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0951 - val_loss: 0.1506\n",
      "Epoch 344/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0866 - val_loss: 0.2850\n",
      "Epoch 345/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1354 - val_loss: 0.5554\n",
      "Epoch 346/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0978 - val_loss: 0.2382\n",
      "Epoch 347/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1199 - val_loss: 0.0968\n",
      "Epoch 348/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1085 - val_loss: 0.2113\n",
      "Epoch 349/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0903 - val_loss: 0.3185\n",
      "Epoch 350/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1000 - val_loss: 0.2254\n",
      "Epoch 351/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1008 - val_loss: 0.1670\n",
      "Epoch 352/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0845 - val_loss: 0.2795\n",
      "Epoch 353/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0889 - val_loss: 0.2128\n",
      "Epoch 354/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0783 - val_loss: 0.3014\n",
      "Epoch 355/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0656 - val_loss: 0.1970\n",
      "Epoch 356/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.2635\n",
      "Epoch 357/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0958 - val_loss: 0.2462\n",
      "Epoch 358/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0889 - val_loss: 0.2535\n",
      "Epoch 359/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0791 - val_loss: 0.0987\n",
      "Epoch 360/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0688 - val_loss: 0.2527\n",
      "Epoch 361/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0917 - val_loss: 0.3135\n",
      "Epoch 362/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0797 - val_loss: 0.2315\n",
      "Epoch 363/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0955 - val_loss: 0.2399\n",
      "Epoch 364/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0723 - val_loss: 0.1950\n",
      "Epoch 365/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0829 - val_loss: 0.2672\n",
      "Epoch 366/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0988 - val_loss: 0.2152\n",
      "Epoch 367/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0675 - val_loss: 0.1051\n",
      "Epoch 368/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1168 - val_loss: 0.1975\n",
      "Epoch 369/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0587 - val_loss: 0.2595\n",
      "Epoch 370/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0507 - val_loss: 0.3122\n",
      "Epoch 371/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1475 - val_loss: 0.1302\n",
      "Epoch 372/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1212 - val_loss: 0.4092\n",
      "Epoch 373/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0905 - val_loss: 0.2289\n",
      "Epoch 374/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0731 - val_loss: 0.4411\n",
      "Epoch 375/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0692 - val_loss: 0.1899\n",
      "Epoch 376/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0824 - val_loss: 0.3426\n",
      "Epoch 377/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0787 - val_loss: 0.2242\n",
      "Epoch 378/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1125 - val_loss: 0.3169\n",
      "Epoch 379/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0933 - val_loss: 0.4004\n",
      "Epoch 380/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0800 - val_loss: 0.3234\n",
      "Epoch 381/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0742 - val_loss: 0.2374\n",
      "Epoch 382/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0590 - val_loss: 0.2343\n",
      "Epoch 383/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0817 - val_loss: 0.2340\n",
      "Epoch 384/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0771 - val_loss: 0.3816\n",
      "Epoch 385/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0713 - val_loss: 0.2146\n",
      "Epoch 386/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0556 - val_loss: 0.1276\n",
      "Epoch 387/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1150 - val_loss: 0.3320\n",
      "Epoch 388/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0870 - val_loss: 0.2505\n",
      "Epoch 389/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0542 - val_loss: 0.1758\n",
      "Epoch 390/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0714 - val_loss: 0.3369\n",
      "Epoch 391/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0666 - val_loss: 0.1851\n",
      "Epoch 392/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0993 - val_loss: 0.3779\n",
      "Epoch 393/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0676 - val_loss: 0.2269\n",
      "Epoch 394/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0545 - val_loss: 0.2112\n",
      "Epoch 395/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0909 - val_loss: 0.2022\n",
      "Epoch 396/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0523 - val_loss: 0.2527\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0881 - val_loss: 0.4342\n",
      "Epoch 398/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1200 - val_loss: 0.3210\n",
      "Epoch 399/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0681 - val_loss: 0.2874\n",
      "Epoch 400/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0505 - val_loss: 0.1934\n",
      "Epoch 401/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1058 - val_loss: 0.3702\n",
      "Epoch 402/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0838 - val_loss: 0.3208\n",
      "Epoch 403/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0630 - val_loss: 0.2846\n",
      "Epoch 404/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0536 - val_loss: 0.1506\n",
      "Epoch 405/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0672 - val_loss: 0.1494\n",
      "Epoch 406/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0965 - val_loss: 0.2036\n",
      "Epoch 407/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0660 - val_loss: 0.2055\n",
      "Epoch 408/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0533 - val_loss: 0.2686\n",
      "Epoch 409/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0724 - val_loss: 0.1827\n",
      "Epoch 410/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0629 - val_loss: 0.3918\n",
      "Epoch 411/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0844 - val_loss: 0.2464\n",
      "Epoch 412/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0656 - val_loss: 0.1518\n",
      "Epoch 413/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0612 - val_loss: 0.3093\n",
      "Epoch 414/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0541 - val_loss: 0.2205\n",
      "Epoch 415/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0585 - val_loss: 0.1015\n",
      "Epoch 416/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0758 - val_loss: 0.2327\n",
      "Epoch 417/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0769 - val_loss: 0.3521\n",
      "Epoch 418/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0615 - val_loss: 0.2287\n",
      "Epoch 419/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0833 - val_loss: 0.2987\n",
      "Epoch 420/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0648 - val_loss: 0.3180\n",
      "Epoch 421/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0605 - val_loss: 0.2429\n",
      "Epoch 422/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0686 - val_loss: 0.1443\n",
      "Epoch 423/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0859 - val_loss: 0.2570\n",
      "Epoch 424/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0599 - val_loss: 0.2214\n",
      "Epoch 425/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0731 - val_loss: 0.1903\n",
      "Epoch 426/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0746 - val_loss: 0.2225\n",
      "Epoch 427/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0483 - val_loss: 0.1640\n",
      "Epoch 428/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.2637 - val_loss: 0.2639\n",
      "Epoch 429/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1473 - val_loss: 0.1156\n",
      "Epoch 430/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1789 - val_loss: 0.3854\n",
      "Epoch 431/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1209 - val_loss: 0.4348\n",
      "Epoch 432/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1471 - val_loss: 0.1958\n",
      "Epoch 433/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0968 - val_loss: 0.3218\n",
      "Epoch 434/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0782 - val_loss: 0.2131\n",
      "Epoch 435/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0755 - val_loss: 0.2385\n",
      "Epoch 436/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0724 - val_loss: 0.2195\n",
      "Epoch 437/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0502 - val_loss: 0.1978\n",
      "Epoch 438/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0891 - val_loss: 0.2450\n",
      "Epoch 439/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0709 - val_loss: 0.2110\n",
      "Epoch 440/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0480 - val_loss: 0.1988\n",
      "Epoch 441/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0588 - val_loss: 0.2770\n",
      "Epoch 442/500\n",
      "108/108 [==============================] - ETA: 0s - loss: 0.072 - 1s 7ms/step - loss: 0.0748 - val_loss: 0.2438\n",
      "Epoch 443/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0639 - val_loss: 0.1647\n",
      "Epoch 444/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0616 - val_loss: 0.2741\n",
      "Epoch 445/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0448 - val_loss: 0.1818\n",
      "Epoch 446/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0740 - val_loss: 0.4134\n",
      "Epoch 447/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0511 - val_loss: 0.3128\n",
      "Epoch 448/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0601 - val_loss: 0.2102\n",
      "Epoch 449/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0362 - val_loss: 0.2275\n",
      "Epoch 450/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0599 - val_loss: 0.2073\n",
      "Epoch 451/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0756 - val_loss: 0.3467\n",
      "Epoch 452/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0489 - val_loss: 0.1682\n",
      "Epoch 453/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0391 - val_loss: 0.1567\n",
      "Epoch 454/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0895 - val_loss: 0.2202\n",
      "Epoch 455/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0636 - val_loss: 0.3013\n",
      "Epoch 456/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0680 - val_loss: 0.2192\n",
      "Epoch 457/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0536 - val_loss: 0.1452\n",
      "Epoch 458/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0507 - val_loss: 0.2285\n",
      "Epoch 459/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0601 - val_loss: 0.2160\n",
      "Epoch 460/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0611 - val_loss: 0.2022\n",
      "Epoch 461/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0566 - val_loss: 0.2296\n",
      "Epoch 462/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0483 - val_loss: 0.2194\n",
      "Epoch 463/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0678 - val_loss: 0.2642\n",
      "Epoch 464/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0375 - val_loss: 0.1999\n",
      "Epoch 465/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0564 - val_loss: 0.2661\n",
      "Epoch 466/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0527 - val_loss: 0.2032\n",
      "Epoch 467/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0476 - val_loss: 0.1973\n",
      "Epoch 468/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0570 - val_loss: 0.4140\n",
      "Epoch 469/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0694 - val_loss: 0.1288\n",
      "Epoch 470/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1710 - val_loss: 0.3366\n",
      "Epoch 471/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1046 - val_loss: 0.1880\n",
      "Epoch 472/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1074 - val_loss: 0.2533\n",
      "Epoch 473/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0851 - val_loss: 0.1625\n",
      "Epoch 474/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0820 - val_loss: 0.3167\n",
      "Epoch 475/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0613 - val_loss: 0.2937\n",
      "Epoch 476/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0574 - val_loss: 0.1274\n",
      "Epoch 477/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0990 - val_loss: 0.3252\n",
      "Epoch 478/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0658 - val_loss: 0.1796\n",
      "Epoch 479/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0951 - val_loss: 0.2280\n",
      "Epoch 480/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0759 - val_loss: 0.3418\n",
      "Epoch 481/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0810 - val_loss: 0.1613\n",
      "Epoch 482/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0588 - val_loss: 0.3400\n",
      "Epoch 483/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0536 - val_loss: 0.1790\n",
      "Epoch 484/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0852 - val_loss: 0.1736\n",
      "Epoch 485/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0587 - val_loss: 0.3601\n",
      "Epoch 486/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0819 - val_loss: 0.2085\n",
      "Epoch 487/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0632 - val_loss: 0.1546\n",
      "Epoch 488/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0620 - val_loss: 0.3772\n",
      "Epoch 489/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0467 - val_loss: 0.2699\n",
      "Epoch 490/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0408 - val_loss: 0.1375\n",
      "Epoch 491/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1370 - val_loss: 0.4354\n",
      "Epoch 492/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1486 - val_loss: 0.2868\n",
      "Epoch 493/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0696 - val_loss: 0.4662\n",
      "Epoch 494/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.1359 - val_loss: 0.2462\n",
      "Epoch 495/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0825 - val_loss: 0.2590\n",
      "Epoch 496/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0677 - val_loss: 0.2926\n",
      "Epoch 497/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0660 - val_loss: 0.2405\n",
      "Epoch 498/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0433 - val_loss: 0.3588\n",
      "Epoch 499/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0507 - val_loss: 0.2113\n",
      "Epoch 500/500\n",
      "108/108 [==============================] - 1s 7ms/step - loss: 0.0451 - val_loss: 0.3149\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 24, 12)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 24)       1800        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_3 (SeqSelfAt (None, 24, 24)       577         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 24)       0           seq_self_attention_3[0][0]       \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 24, 24)       48          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           6924        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 588)          0           dropout_3[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            589         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,940\n",
      "Trainable params: 9,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Predict time:  0.36017370223999023\n",
      "RMSE:  4.7313811105292\n",
      "RMSE2:  1.974571793818967\n",
      "MAE:  3.430992392698924\n",
      "MAE2:  3.430992392698924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse score')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=0.001,decay = 0.0001)\n",
    "print('Train...')\n",
    "# model.compile(optimizer = opt , loss=\"mse\")\n",
    "model.compile(optimizer = \"adam\" , loss=\"mse\")\n",
    "history = model.fit([x_train,x_train], y_train, epochs = 500, batch_size=8, validation_split=0.1, shuffle=True)\n",
    "# history = model.fit(x_train, y_train, epochs = 500, batch_size=6, validation_split=0.1, shuffle=True)\n",
    "model.summary()\n",
    "#Save Model\n",
    "model.save('GRU_Single_Attention_model_South.h5')  # creates a HDF5 file \n",
    "del model\n",
    "\n",
    "custom_ob = {'LayerNormalization': LayerNormalization , 'SeqSelfAttention':SeqSelfAttention}\n",
    "model = load_model('GRU_Single_Attention_model_South.h5', custom_objects=custom_ob)\n",
    "t1 = time.time()\n",
    "# y_pred = model.predict([x_test,x_test])\n",
    "y_pred2 = model.predict(x_test)\n",
    "y_pred = model.predict(x_train)\n",
    "t2 = time.time()\n",
    "print('Predict time: ',t2-t1)\n",
    "y_pred = scaler.inverse_transform(y_pred)#Undo scaling\n",
    "rmse_lstm2 = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print('RMSE: ',rmse_lstm)\n",
    "print('RMSE2: ',rmse_lstm2)\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('MAE: ',mae)\n",
    "print('MAE2: ',mae)\n",
    "# r22 =  r2_score(y_test, y_pred2)\n",
    "# r2 =  r2_score(y_train, y_pred)\n",
    "# print('R-square: ',r2)\n",
    "# print('R-square2: ',r22)\n",
    "\n",
    "# n = len(y_test)\n",
    "# p = 12\n",
    "# Adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "# Adj_r22 = 1-(1-r22)*(n-1)/(n-p-1)\n",
    "# print('Adj R-square: ',Adj_r2)\n",
    "# print('Adj R-square2: ',Adj_r22)\n",
    "\n",
    "plt.plot(history.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"No. Of Epochs\")\n",
    "plt.ylabel(\"mse score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b7bc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/200\n",
      "108/108 [==============================] - 2s 20ms/step - loss: 1.9559 - val_loss: 1.8557\n",
      "Epoch 2/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.8942 - val_loss: 1.7626\n",
      "Epoch 3/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.8272 - val_loss: 1.6581\n",
      "Epoch 4/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.7749 - val_loss: 1.5638\n",
      "Epoch 5/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.7128 - val_loss: 1.4755\n",
      "Epoch 6/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.7014 - val_loss: 1.4040\n",
      "Epoch 7/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.6071 - val_loss: 1.3177\n",
      "Epoch 8/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.5587 - val_loss: 1.2474\n",
      "Epoch 9/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.5035 - val_loss: 1.1799\n",
      "Epoch 10/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.4642 - val_loss: 1.1147\n",
      "Epoch 11/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.4519 - val_loss: 1.0566\n",
      "Epoch 12/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3676 - val_loss: 1.0091\n",
      "Epoch 13/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3425 - val_loss: 0.9785\n",
      "Epoch 14/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2929 - val_loss: 0.9426\n",
      "Epoch 15/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3091 - val_loss: 0.9127\n",
      "Epoch 16/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2666 - val_loss: 0.8853\n",
      "Epoch 17/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2785 - val_loss: 0.8676\n",
      "Epoch 18/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2256 - val_loss: 0.8513\n",
      "Epoch 19/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2192 - val_loss: 0.8359\n",
      "Epoch 20/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.1910 - val_loss: 0.8145\n",
      "Epoch 21/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.1896 - val_loss: 0.7948\n",
      "Epoch 22/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.1650 - val_loss: 0.7774\n",
      "Epoch 23/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.1768 - val_loss: 0.7607\n",
      "Epoch 24/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.1073 - val_loss: 0.7429\n",
      "Epoch 25/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.1156 - val_loss: 0.7237\n",
      "Epoch 26/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.1096 - val_loss: 0.7147\n",
      "Epoch 27/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0594 - val_loss: 0.6997\n",
      "Epoch 28/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0900 - val_loss: 0.7009\n",
      "Epoch 29/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0831 - val_loss: 0.6907\n",
      "Epoch 30/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0518 - val_loss: 0.6830\n",
      "Epoch 31/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0692 - val_loss: 0.6658\n",
      "Epoch 32/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0414 - val_loss: 0.6587\n",
      "Epoch 33/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0813 - val_loss: 0.6521\n",
      "Epoch 34/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0641 - val_loss: 0.6564\n",
      "Epoch 35/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9910 - val_loss: 0.6425\n",
      "Epoch 36/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0156 - val_loss: 0.6365\n",
      "Epoch 37/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0341 - val_loss: 0.6235\n",
      "Epoch 38/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9691 - val_loss: 0.6130\n",
      "Epoch 39/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0154 - val_loss: 0.6071\n",
      "Epoch 40/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0258 - val_loss: 0.5962\n",
      "Epoch 41/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9860 - val_loss: 0.5893\n",
      "Epoch 42/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9205 - val_loss: 0.5917\n",
      "Epoch 43/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9288 - val_loss: 0.5855\n",
      "Epoch 44/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9507 - val_loss: 0.5868\n",
      "Epoch 45/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9372 - val_loss: 0.5823\n",
      "Epoch 46/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9282 - val_loss: 0.5847\n",
      "Epoch 47/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9212 - val_loss: 0.5867\n",
      "Epoch 48/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9218 - val_loss: 0.5736\n",
      "Epoch 49/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9355 - val_loss: 0.5686\n",
      "Epoch 50/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9321 - val_loss: 0.5700\n",
      "Epoch 51/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8997 - val_loss: 0.5759\n",
      "Epoch 52/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8602 - val_loss: 0.5583\n",
      "Epoch 53/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8620 - val_loss: 0.5481\n",
      "Epoch 54/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8984 - val_loss: 0.5374\n",
      "Epoch 55/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8749 - val_loss: 0.5374\n",
      "Epoch 56/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8483 - val_loss: 0.5270\n",
      "Epoch 57/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9008 - val_loss: 0.5154\n",
      "Epoch 58/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8447 - val_loss: 0.5042\n",
      "Epoch 59/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8600 - val_loss: 0.5016\n",
      "Epoch 60/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8441 - val_loss: 0.5148\n",
      "Epoch 61/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8472 - val_loss: 0.5060\n",
      "Epoch 62/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8357 - val_loss: 0.5044\n",
      "Epoch 63/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9049 - val_loss: 0.5040\n",
      "Epoch 64/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8484 - val_loss: 0.5135\n",
      "Epoch 65/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8200 - val_loss: 0.4962\n",
      "Epoch 66/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8270 - val_loss: 0.4835\n",
      "Epoch 67/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8166 - val_loss: 0.4673\n",
      "Epoch 68/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7576 - val_loss: 0.4822\n",
      "Epoch 69/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8100 - val_loss: 0.4751\n",
      "Epoch 70/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8173 - val_loss: 0.4546\n",
      "Epoch 71/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7816 - val_loss: 0.4622\n",
      "Epoch 72/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8039 - val_loss: 0.4754\n",
      "Epoch 73/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7718 - val_loss: 0.4646\n",
      "Epoch 74/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7279 - val_loss: 0.4614\n",
      "Epoch 75/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7544 - val_loss: 0.4484\n",
      "Epoch 76/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7489 - val_loss: 0.4908\n",
      "Epoch 77/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7667 - val_loss: 0.4717\n",
      "Epoch 78/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7790 - val_loss: 0.4147\n",
      "Epoch 79/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7140 - val_loss: 0.4588\n",
      "Epoch 80/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7636 - val_loss: 0.4100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8044 - val_loss: 0.3865\n",
      "Epoch 82/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7172 - val_loss: 0.4068\n",
      "Epoch 83/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7261 - val_loss: 0.3699\n",
      "Epoch 84/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7172 - val_loss: 0.4297\n",
      "Epoch 85/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6807 - val_loss: 0.3997\n",
      "Epoch 86/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6905 - val_loss: 0.4252\n",
      "Epoch 87/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7025 - val_loss: 0.4429\n",
      "Epoch 88/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7634 - val_loss: 0.4551\n",
      "Epoch 89/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7065 - val_loss: 0.3661\n",
      "Epoch 90/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7192 - val_loss: 0.3408\n",
      "Epoch 91/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6721 - val_loss: 0.3723\n",
      "Epoch 92/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6420 - val_loss: 0.3350\n",
      "Epoch 93/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6479 - val_loss: 0.3318\n",
      "Epoch 94/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5912 - val_loss: 0.3171\n",
      "Epoch 95/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5969 - val_loss: 0.3853\n",
      "Epoch 96/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6019 - val_loss: 0.3806\n",
      "Epoch 97/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6196 - val_loss: 0.4013\n",
      "Epoch 98/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6632 - val_loss: 0.3806\n",
      "Epoch 99/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5632 - val_loss: 0.2980\n",
      "Epoch 100/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5771 - val_loss: 0.3769\n",
      "Epoch 101/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6272 - val_loss: 0.3860\n",
      "Epoch 102/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6111 - val_loss: 0.4220\n",
      "Epoch 103/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6161 - val_loss: 0.4129\n",
      "Epoch 104/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5460 - val_loss: 0.3125\n",
      "Epoch 105/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5177 - val_loss: 0.3753\n",
      "Epoch 106/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5273 - val_loss: 0.4154\n",
      "Epoch 107/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5790 - val_loss: 0.3665\n",
      "Epoch 108/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5747 - val_loss: 0.4462\n",
      "Epoch 109/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5481 - val_loss: 0.3683\n",
      "Epoch 110/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5154 - val_loss: 0.4799\n",
      "Epoch 111/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5288 - val_loss: 0.5076\n",
      "Epoch 112/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5019 - val_loss: 0.4201\n",
      "Epoch 113/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5781 - val_loss: 0.4045\n",
      "Epoch 114/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5333 - val_loss: 0.4789\n",
      "Epoch 115/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5198 - val_loss: 0.3416\n",
      "Epoch 116/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5369 - val_loss: 0.3240\n",
      "Epoch 117/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5186 - val_loss: 0.3898\n",
      "Epoch 118/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4886 - val_loss: 0.4207\n",
      "Epoch 119/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4700 - val_loss: 0.3148\n",
      "Epoch 120/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5453 - val_loss: 0.4440\n",
      "Epoch 121/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5254 - val_loss: 0.4859\n",
      "Epoch 122/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4535 - val_loss: 0.4941\n",
      "Epoch 123/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5511 - val_loss: 0.5062\n",
      "Epoch 124/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5314 - val_loss: 0.5043\n",
      "Epoch 125/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4431 - val_loss: 0.3601\n",
      "Epoch 126/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5794 - val_loss: 0.5032\n",
      "Epoch 127/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5666 - val_loss: 0.4148\n",
      "Epoch 128/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4446 - val_loss: 0.4334\n",
      "Epoch 129/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4964 - val_loss: 0.5744\n",
      "Epoch 130/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5432 - val_loss: 0.3976\n",
      "Epoch 131/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5478 - val_loss: 0.5673\n",
      "Epoch 132/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5065 - val_loss: 0.5019\n",
      "Epoch 133/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4961 - val_loss: 0.5883\n",
      "Epoch 134/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5145 - val_loss: 0.5411\n",
      "Epoch 135/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4531 - val_loss: 0.5393\n",
      "Epoch 136/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5226 - val_loss: 0.5706\n",
      "Epoch 137/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4553 - val_loss: 0.6253\n",
      "Epoch 138/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4968 - val_loss: 0.3941\n",
      "Epoch 139/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4912 - val_loss: 0.5369\n",
      "Epoch 140/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4884 - val_loss: 0.4081\n",
      "Epoch 141/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4730 - val_loss: 0.4120\n",
      "Epoch 142/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4256 - val_loss: 0.4508\n",
      "Epoch 143/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4562 - val_loss: 0.6793\n",
      "Epoch 144/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4567 - val_loss: 0.4405\n",
      "Epoch 145/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4565 - val_loss: 0.5653\n",
      "Epoch 146/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5085 - val_loss: 0.4656\n",
      "Epoch 147/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5031 - val_loss: 0.4851\n",
      "Epoch 148/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4699 - val_loss: 0.3749\n",
      "Epoch 149/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5183 - val_loss: 0.4602\n",
      "Epoch 150/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5124 - val_loss: 0.5167\n",
      "Epoch 151/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5024 - val_loss: 0.4311\n",
      "Epoch 152/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3904 - val_loss: 0.4534\n",
      "Epoch 153/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4642 - val_loss: 0.6599\n",
      "Epoch 154/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4492 - val_loss: 0.4687\n",
      "Epoch 155/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5073 - val_loss: 0.4181\n",
      "Epoch 156/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4944 - val_loss: 0.5095\n",
      "Epoch 157/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4743 - val_loss: 0.6519\n",
      "Epoch 158/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4673 - val_loss: 0.5568\n",
      "Epoch 159/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4559 - val_loss: 0.7044\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4764 - val_loss: 0.4089\n",
      "Epoch 161/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4010 - val_loss: 0.4288\n",
      "Epoch 162/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4695 - val_loss: 0.6969\n",
      "Epoch 163/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4916 - val_loss: 0.4061\n",
      "Epoch 164/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4758 - val_loss: 0.5734\n",
      "Epoch 165/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4284 - val_loss: 0.5924\n",
      "Epoch 166/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4475 - val_loss: 0.7127\n",
      "Epoch 167/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4720 - val_loss: 0.5991\n",
      "Epoch 168/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4446 - val_loss: 0.4993\n",
      "Epoch 169/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4152 - val_loss: 0.4706\n",
      "Epoch 170/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4923 - val_loss: 0.4844\n",
      "Epoch 171/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4999 - val_loss: 0.6241\n",
      "Epoch 172/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4469 - val_loss: 0.6111\n",
      "Epoch 173/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4792 - val_loss: 0.4164\n",
      "Epoch 174/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4250 - val_loss: 0.4345\n",
      "Epoch 175/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4375 - val_loss: 0.4713\n",
      "Epoch 176/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4650 - val_loss: 0.7688\n",
      "Epoch 177/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4517 - val_loss: 0.8929\n",
      "Epoch 178/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4889 - val_loss: 0.4262\n",
      "Epoch 179/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3952 - val_loss: 0.5176\n",
      "Epoch 180/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3666 - val_loss: 0.6229\n",
      "Epoch 181/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4197 - val_loss: 0.6480\n",
      "Epoch 182/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4361 - val_loss: 0.5934\n",
      "Epoch 183/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4035 - val_loss: 0.5322\n",
      "Epoch 184/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3679 - val_loss: 0.4123\n",
      "Epoch 185/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3367 - val_loss: 0.6875\n",
      "Epoch 186/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4465 - val_loss: 0.4508\n",
      "Epoch 187/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4223 - val_loss: 0.7353\n",
      "Epoch 188/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4811 - val_loss: 0.6169\n",
      "Epoch 189/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3780 - val_loss: 0.4903\n",
      "Epoch 190/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4196 - val_loss: 0.5163\n",
      "Epoch 191/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4122 - val_loss: 0.6332\n",
      "Epoch 192/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4120 - val_loss: 0.6610\n",
      "Epoch 193/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.5012 - val_loss: 0.7263\n",
      "Epoch 194/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4768 - val_loss: 0.4380\n",
      "Epoch 195/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3959 - val_loss: 0.4753\n",
      "Epoch 196/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.5097 - val_loss: 0.5743\n",
      "Epoch 197/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3683 - val_loss: 0.7061\n",
      "Epoch 198/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4144 - val_loss: 0.6459\n",
      "Epoch 199/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.4418 - val_loss: 0.6484\n",
      "Epoch 200/200\n",
      "108/108 [==============================] - 0s 3ms/step - loss: 0.3657 - val_loss: 0.4972\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_8 (Bidirection (None, 24, 12)            684       \n",
      "_________________________________________________________________\n",
      "layer_normalization_6 (Layer (None, 24, 12)            24        \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 12)                684       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,405\n",
      "Trainable params: 1,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Saved\n",
      "Predict time:  0.343949556350708\n",
      "RMSE:  4.106229483148998\n",
      "RMSE2:  2.6541041331507977\n",
      "MAE:  3.44813921948274\n",
      "MAE2:  3.44813921948274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse score')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "init = glorot_normal(seed=None) # 給 LSTM\n",
    "init_d = RandomUniform(minval=-0.05, maxval=0.05) # 給 Dense layer\n",
    "nadam = optimizers.Nadam(lr=0.0015,clipvalue=0.5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(6, kernel_initializer=init ,return_sequences = True,kernel_regularizer=regularizers.l2(0.01)\n",
    "                             ,recurrent_regularizer = regularizers.l2(0.01) ,input_shape=(x_train.shape[1],x_train.shape[2]))))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Bidirectional(GRU(6,kernel_initializer=init,kernel_regularizer=regularizers.l2(0.01),recurrent_regularizer = regularizers.l2(0.01))))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1, kernel_initializer=init_d))\n",
    "model.compile(optimizer = nadam , loss=\"mse\")\n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size=24, validation_split=0.1, shuffle=True)\n",
    "#model summary\n",
    "model.summary()\n",
    "#Save Model\n",
    "model.save('GRU_model_South.h5')  # creates a HDF5 file \n",
    "print('Model Saved')\n",
    "del model  # deletes the existing model\n",
    "\n",
    "custom_ob = {'LayerNormalization': LayerNormalization , 'SeqSelfAttention':SeqSelfAttention}\n",
    "model = load_model('GRU_model_South.h5', custom_objects=custom_ob)\n",
    "t1 = time.time()\n",
    "# y_pred = model.predict([x_test,x_test])\n",
    "y_pred2 = model.predict(x_test)\n",
    "y_pred = model.predict(x_train)\n",
    "t2 = time.time()\n",
    "print('Predict time: ',t2-t1)\n",
    "y_pred = scaler.inverse_transform(y_pred)#Undo scaling\n",
    "rmse_lstm2 = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print('RMSE: ',rmse_lstm)\n",
    "print('RMSE2: ',rmse_lstm2)\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('MAE: ',mae)\n",
    "print('MAE2: ',mae)\n",
    "# r22 =  r2_score(y_test, y_pred2)\n",
    "# r2 =  r2_score(y_train, y_pred)\n",
    "# print('R-square: ',r2)\n",
    "# print('R-square2: ',r22)\n",
    "\n",
    "# n = len(y_test)\n",
    "# p = 12\n",
    "# Adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "# Adj_r22 = 1-(1-r22)*(n-1)/(n-p-1)\n",
    "# print('Adj R-square: ',Adj_r2)\n",
    "# print('Adj R-square2: ',Adj_r22)\n",
    "\n",
    "plt.plot(history.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"No. Of Epochs\")\n",
    "plt.ylabel(\"mse score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551db303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709449f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
