{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9b4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from tcn import TCN\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential , load_model , Model\n",
    "from keras.layers import Dense, Dropout , LSTM , Bidirectional ,GRU ,Flatten,Add,BatchNormalization\n",
    "from keras_layer_normalization import LayerNormalization\n",
    "from keras.initializers import  glorot_normal, RandomUniform\n",
    "from keras import optimizers,Input\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f352f3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160, 13) (144, 13) (40, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c74a74d036946d99d437c75ff0b8ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:44: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7903e7f113d4b69a54963c0048cca5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:\n",
      "(120, 24, 12) (120,)\n",
      "Test size:\n",
      "(16, 24, 12) (16,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"station_bike_Doric.csv\")\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df = df.set_index(\"timestamp\")\n",
    "#df.head()\n",
    "\n",
    "df[\"hour\"] = df.index.hour\n",
    "df[\"day_of_month\"] = df.index.day\n",
    "df[\"day_of_week\"]  = df.index.dayofweek\n",
    "df[\"month\"] = df.index.month\n",
    "\n",
    "training_data_len = math.ceil(len(df) * 0.9) # taking 90% of data to train and 10% of data to test\n",
    "testing_data_len = len(df) - training_data_len\n",
    "\n",
    "time_steps = 24\n",
    "train, test = df.iloc[0:training_data_len], df.iloc[(training_data_len-time_steps):len(df)]\n",
    "print(df.shape, train.shape, test.shape)\n",
    "train_trans = train[['t1','t2', 'hum', 'wind_speed']].to_numpy()\n",
    "test_trans = test[['t1','t2', 'hum', 'wind_speed']].to_numpy()\n",
    "\n",
    "scaler = RobustScaler() # Handles outliers\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1)) # scale to (0,1)\n",
    "train.loc[:, ['t1','t2','hum', 'wind_speed']]=scaler.fit_transform(train_trans)\n",
    "test.loc[:, ['t1','t2', 'hum', 'wind_speed']]=scaler.fit_transform(test_trans)\n",
    "\n",
    "train['cnt'] = scaler.fit_transform(train[['cnt']])\n",
    "test['cnt'] = scaler.fit_transform(test[['cnt']])\n",
    "\n",
    "#Split the data into x_train and y_train data sets\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in tqdm(range(len(train) - time_steps)):\n",
    "    x_train.append(train.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n",
    "    y_train.append(train.loc[:,'cnt'].iloc[i + time_steps])\n",
    "\n",
    "#Convert x_train and y_train to numpy arrays\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "#Create the x_test and y_test data sets\n",
    "x_test = []\n",
    "y_test = df.loc[:,'cnt'].iloc[training_data_len:len(df)]\n",
    "\n",
    "for i in tqdm(range(len(test) - time_steps)):\n",
    "    x_test.append(test.drop(columns='cnt').iloc[i:i + time_steps].to_numpy())\n",
    "    # y_test.append(test.loc[:,'cnt'].iloc[i + time_steps])\n",
    "\n",
    "#Convert x_test and y_test to numpy arrays\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# All 12 columns of the data\n",
    "print('Train size:')\n",
    "print(x_train.shape, y_train.shape)\n",
    "print('Test size:')\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "667c5e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 24, 12)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 24)       1800        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_3 (SeqSelfAt (None, 24, 24)       577         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 24)       0           seq_self_attention_3[0][0]       \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 24, 24)       48          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           6924        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 588)          0           dropout_3[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            589         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,940\n",
      "Trainable params: 9,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "init = glorot_normal(seed=None) # 給 GRU\n",
    "init_d = RandomUniform(minval=-0.05, maxval=0.05) # 給 Dense layer\n",
    "\n",
    "def Encoder(layer):\n",
    "    shortcut = layer\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = Add()([layer,shortcut])\n",
    "    layer = LayerNormalization()(layer)\n",
    "    layer = Flatten()(layer)\n",
    "    \n",
    "    shortcut2 = layer\n",
    "    layer = Dense(12,kernel_initializer=init_d)(layer)\n",
    "    layer = Dropout(0.2)(layer)\n",
    "    layer = Concatenate()([layer,shortcut2])\n",
    "    output = Dense(1,kernel_initializer=init_d)(layer)\n",
    "    return output\n",
    "\n",
    "def Decoder(layer):\n",
    "    shortcut = layer\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = Add()([layer,shortcut])\n",
    "    layer = LayerNormalization()(layer)\n",
    "    layer = SeqSelfAttention(\n",
    "                     attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL,\n",
    "                     kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     bias_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                     attention_regularizer_weight=0.0001)(layer)\n",
    "    layer = LayerNormalization()(layer)\n",
    "    \n",
    "    layer = Flatten()(layer)\n",
    "    shortcut2 = layer\n",
    "    layer = Dense(10,kernel_initializer=init_d)(layer)\n",
    "    #layer = Dropout(0.2)(layer)\n",
    "    layer = Concatenate()([layer,shortcut2])\n",
    "    output = Dense(1,kernel_initializer=init_d)(layer)\n",
    "    return output\n",
    "\n",
    "def Bi_GRU(layer,unit):\n",
    "    output = Bidirectional(GRU(unit, dropout=0.1, recurrent_dropout=0.1, return_sequences=True,\n",
    "                            kernel_initializer=init))(layer)\n",
    "    return output\n",
    "\n",
    "#start = Input(shape = (x_train.shape[1],x_train.shape[2]))\n",
    "start = Input(shape = (x_train.shape[1:]))\n",
    "start2 = Input(shape = (x_train.shape[1:]))\n",
    "x = Bi_GRU(start,12)\n",
    "x = Encoder(x)\n",
    "\n",
    "# y = Bi_GRU(start2,8)\n",
    "# y = Decoder(y)\n",
    "\n",
    "#Merge = Add()([x,x])\n",
    "Last = Dense(1)(x)\n",
    "model = Model([start,start2] , Last)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f52bf314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/500\n",
      "108/108 [==============================] - 2s 17ms/step - loss: 2.1082 - val_loss: 1.1366\n",
      "Epoch 2/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.9434 - val_loss: 1.1355\n",
      "Epoch 3/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.8796 - val_loss: 1.3978\n",
      "Epoch 4/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.8389 - val_loss: 0.8929\n",
      "Epoch 5/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.7274 - val_loss: 1.3223\n",
      "Epoch 6/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.7095 - val_loss: 0.8915\n",
      "Epoch 7/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.4130 - val_loss: 1.2995\n",
      "Epoch 8/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4279 - val_loss: 0.7498\n",
      "Epoch 9/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.2875 - val_loss: 0.6098\n",
      "Epoch 10/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.3606 - val_loss: 1.2885\n",
      "Epoch 11/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.2015 - val_loss: 0.8485\n",
      "Epoch 12/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.1719 - val_loss: 0.6245\n",
      "Epoch 13/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.1194 - val_loss: 1.3238\n",
      "Epoch 14/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.3019 - val_loss: 1.0361\n",
      "Epoch 15/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0654 - val_loss: 0.6515\n",
      "Epoch 16/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8433 - val_loss: 0.8368\n",
      "Epoch 17/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9672 - val_loss: 0.6441\n",
      "Epoch 18/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9737 - val_loss: 0.7787\n",
      "Epoch 19/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7895 - val_loss: 0.7103\n",
      "Epoch 20/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8143 - val_loss: 0.5879\n",
      "Epoch 21/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7363 - val_loss: 1.0436\n",
      "Epoch 22/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0119 - val_loss: 0.5570\n",
      "Epoch 23/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8208 - val_loss: 0.5636\n",
      "Epoch 24/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7478 - val_loss: 0.6889\n",
      "Epoch 25/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7100 - val_loss: 0.6693\n",
      "Epoch 26/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8398 - val_loss: 0.7898\n",
      "Epoch 27/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6688 - val_loss: 0.5691\n",
      "Epoch 28/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6661 - val_loss: 0.4893\n",
      "Epoch 29/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5318 - val_loss: 0.6526\n",
      "Epoch 30/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5629 - val_loss: 0.7415\n",
      "Epoch 31/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5114 - val_loss: 0.5975\n",
      "Epoch 32/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5874 - val_loss: 0.7205\n",
      "Epoch 33/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6228 - val_loss: 0.6607\n",
      "Epoch 34/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8845 - val_loss: 0.6878\n",
      "Epoch 35/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4701 - val_loss: 0.6343\n",
      "Epoch 36/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4396 - val_loss: 0.7622\n",
      "Epoch 37/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5524 - val_loss: 0.7895\n",
      "Epoch 38/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6179 - val_loss: 0.6609\n",
      "Epoch 39/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5928 - val_loss: 0.9383\n",
      "Epoch 40/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4593 - val_loss: 0.6746\n",
      "Epoch 41/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5144 - val_loss: 0.7003\n",
      "Epoch 42/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5392 - val_loss: 0.6264\n",
      "Epoch 43/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3967 - val_loss: 0.6427\n",
      "Epoch 44/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4467 - val_loss: 0.8119\n",
      "Epoch 45/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4676 - val_loss: 0.5354\n",
      "Epoch 46/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3430 - val_loss: 0.5733\n",
      "Epoch 47/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7853 - val_loss: 0.5823\n",
      "Epoch 48/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5972 - val_loss: 0.5318\n",
      "Epoch 49/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4274 - val_loss: 0.5262\n",
      "Epoch 50/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4057 - val_loss: 0.6037\n",
      "Epoch 51/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4317 - val_loss: 0.7551\n",
      "Epoch 52/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4681 - val_loss: 0.5364\n",
      "Epoch 53/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5978 - val_loss: 0.6232\n",
      "Epoch 54/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5643 - val_loss: 0.7676\n",
      "Epoch 55/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5490 - val_loss: 0.6338\n",
      "Epoch 56/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4186 - val_loss: 0.5907\n",
      "Epoch 57/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3001 - val_loss: 0.4992\n",
      "Epoch 58/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3571 - val_loss: 0.4956\n",
      "Epoch 59/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5303 - val_loss: 0.6568\n",
      "Epoch 60/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4216 - val_loss: 0.6806\n",
      "Epoch 61/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3812 - val_loss: 0.5081\n",
      "Epoch 62/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5418 - val_loss: 0.7745\n",
      "Epoch 63/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5129 - val_loss: 0.6464\n",
      "Epoch 64/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4898 - val_loss: 0.5648\n",
      "Epoch 65/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4258 - val_loss: 0.5105\n",
      "Epoch 66/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4103 - val_loss: 0.6490\n",
      "Epoch 67/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4039 - val_loss: 0.5039\n",
      "Epoch 68/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4137 - val_loss: 0.5567\n",
      "Epoch 69/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4263 - val_loss: 0.5001\n",
      "Epoch 70/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5050 - val_loss: 0.5949\n",
      "Epoch 71/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4193 - val_loss: 0.6140\n",
      "Epoch 72/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3912 - val_loss: 0.6663\n",
      "Epoch 73/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3234 - val_loss: 0.5681\n",
      "Epoch 74/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3950 - val_loss: 0.5694\n",
      "Epoch 75/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2973 - val_loss: 0.5625\n",
      "Epoch 76/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3846 - val_loss: 0.5670\n",
      "Epoch 77/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3295 - val_loss: 0.5021\n",
      "Epoch 78/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3505 - val_loss: 0.6264\n",
      "Epoch 79/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4007 - val_loss: 0.6374\n",
      "Epoch 80/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2916 - val_loss: 0.5661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5347 - val_loss: 0.5937\n",
      "Epoch 82/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4740 - val_loss: 0.6353\n",
      "Epoch 83/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4580 - val_loss: 0.6570\n",
      "Epoch 84/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4213 - val_loss: 0.4968\n",
      "Epoch 85/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4134 - val_loss: 0.4254\n",
      "Epoch 86/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4608 - val_loss: 0.5577\n",
      "Epoch 87/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3741 - val_loss: 0.6232\n",
      "Epoch 88/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3933 - val_loss: 0.5422\n",
      "Epoch 89/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3972 - val_loss: 0.5595\n",
      "Epoch 90/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4183 - val_loss: 0.6186\n",
      "Epoch 91/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3150 - val_loss: 0.6785\n",
      "Epoch 92/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3310 - val_loss: 0.6520\n",
      "Epoch 93/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4468 - val_loss: 0.5695\n",
      "Epoch 94/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4340 - val_loss: 0.5830\n",
      "Epoch 95/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5816 - val_loss: 0.6985\n",
      "Epoch 96/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4202 - val_loss: 0.6143\n",
      "Epoch 97/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3053 - val_loss: 0.5130\n",
      "Epoch 98/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2707 - val_loss: 0.5489\n",
      "Epoch 99/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3075 - val_loss: 0.7119\n",
      "Epoch 100/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2651 - val_loss: 0.4752\n",
      "Epoch 101/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2101 - val_loss: 0.5260\n",
      "Epoch 102/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4907 - val_loss: 0.7402\n",
      "Epoch 103/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2188 - val_loss: 0.7468\n",
      "Epoch 104/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2697 - val_loss: 0.5729\n",
      "Epoch 105/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3083 - val_loss: 0.5388\n",
      "Epoch 106/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2784 - val_loss: 0.5309\n",
      "Epoch 107/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2641 - val_loss: 0.4782\n",
      "Epoch 108/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2112 - val_loss: 0.5147\n",
      "Epoch 109/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4438 - val_loss: 0.4455\n",
      "Epoch 110/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4562 - val_loss: 0.4528\n",
      "Epoch 111/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2666 - val_loss: 0.4593\n",
      "Epoch 112/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2586 - val_loss: 0.5330\n",
      "Epoch 113/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2136 - val_loss: 0.5088\n",
      "Epoch 114/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.5043\n",
      "Epoch 115/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3569 - val_loss: 0.5126\n",
      "Epoch 116/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3691 - val_loss: 0.5881\n",
      "Epoch 117/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3331 - val_loss: 0.5352\n",
      "Epoch 118/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4063 - val_loss: 0.6191\n",
      "Epoch 119/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3824 - val_loss: 0.5264\n",
      "Epoch 120/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2299 - val_loss: 0.4249\n",
      "Epoch 121/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2691 - val_loss: 0.5640\n",
      "Epoch 122/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2438 - val_loss: 0.5283\n",
      "Epoch 123/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2403 - val_loss: 0.5107\n",
      "Epoch 124/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3565 - val_loss: 0.5108\n",
      "Epoch 125/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2673 - val_loss: 0.6088\n",
      "Epoch 126/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3278 - val_loss: 0.5057\n",
      "Epoch 127/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3092 - val_loss: 0.5386\n",
      "Epoch 128/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2419 - val_loss: 0.7083\n",
      "Epoch 129/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2863 - val_loss: 0.4934\n",
      "Epoch 130/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3308 - val_loss: 0.6412\n",
      "Epoch 131/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3074 - val_loss: 0.6007\n",
      "Epoch 132/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2762 - val_loss: 0.6412\n",
      "Epoch 133/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3923 - val_loss: 0.4779\n",
      "Epoch 134/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2701 - val_loss: 0.5767\n",
      "Epoch 135/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3392 - val_loss: 0.7138\n",
      "Epoch 136/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4719 - val_loss: 0.5902\n",
      "Epoch 137/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.4338 - val_loss: 0.7594\n",
      "Epoch 138/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3016 - val_loss: 0.4932\n",
      "Epoch 139/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2028 - val_loss: 0.4307\n",
      "Epoch 140/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2223 - val_loss: 0.6930\n",
      "Epoch 141/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2367 - val_loss: 0.5318\n",
      "Epoch 142/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2911 - val_loss: 0.5850\n",
      "Epoch 143/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3497 - val_loss: 0.6236\n",
      "Epoch 144/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3482 - val_loss: 0.5610\n",
      "Epoch 145/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3654 - val_loss: 0.7563\n",
      "Epoch 146/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2922 - val_loss: 0.7046\n",
      "Epoch 147/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2578 - val_loss: 0.5187\n",
      "Epoch 148/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3768 - val_loss: 0.5415\n",
      "Epoch 149/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3672 - val_loss: 0.6108\n",
      "Epoch 150/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2183 - val_loss: 0.5021\n",
      "Epoch 151/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2926 - val_loss: 0.4551\n",
      "Epoch 152/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2318 - val_loss: 0.7088\n",
      "Epoch 153/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2870 - val_loss: 0.5296\n",
      "Epoch 154/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.4734\n",
      "Epoch 155/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2200 - val_loss: 0.4028\n",
      "Epoch 156/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3082 - val_loss: 0.5748\n",
      "Epoch 157/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2714 - val_loss: 0.5255\n",
      "Epoch 158/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2756 - val_loss: 0.5023\n",
      "Epoch 159/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3937 - val_loss: 0.5799\n",
      "Epoch 160/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2766 - val_loss: 0.5480\n",
      "Epoch 161/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2023 - val_loss: 0.4568\n",
      "Epoch 162/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2388 - val_loss: 0.6385\n",
      "Epoch 163/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3320 - val_loss: 0.4409\n",
      "Epoch 164/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2562 - val_loss: 0.5768\n",
      "Epoch 165/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2899 - val_loss: 0.4944\n",
      "Epoch 166/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2215 - val_loss: 0.5470\n",
      "Epoch 167/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2313 - val_loss: 0.5437\n",
      "Epoch 168/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1967 - val_loss: 0.4485\n",
      "Epoch 169/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3294 - val_loss: 0.6091\n",
      "Epoch 170/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2749 - val_loss: 0.6656\n",
      "Epoch 171/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1851 - val_loss: 0.6362\n",
      "Epoch 172/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3269 - val_loss: 0.5326\n",
      "Epoch 173/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2141 - val_loss: 0.7996\n",
      "Epoch 174/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2639 - val_loss: 0.6723\n",
      "Epoch 175/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3396 - val_loss: 0.5793\n",
      "Epoch 176/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2355 - val_loss: 0.5457\n",
      "Epoch 177/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3175 - val_loss: 0.6197\n",
      "Epoch 178/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3282 - val_loss: 0.5331\n",
      "Epoch 179/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2755 - val_loss: 0.4967\n",
      "Epoch 180/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1992 - val_loss: 0.5186\n",
      "Epoch 181/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1686 - val_loss: 0.5336\n",
      "Epoch 182/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2460 - val_loss: 0.7600\n",
      "Epoch 183/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2525 - val_loss: 0.5581\n",
      "Epoch 184/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3039 - val_loss: 0.5650\n",
      "Epoch 185/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4092 - val_loss: 0.5915\n",
      "Epoch 186/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2062 - val_loss: 0.5317\n",
      "Epoch 187/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1975 - val_loss: 0.4804\n",
      "Epoch 188/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2202 - val_loss: 0.4722\n",
      "Epoch 189/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2533 - val_loss: 0.4681\n",
      "Epoch 190/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2264 - val_loss: 0.5214\n",
      "Epoch 191/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2117 - val_loss: 0.5754\n",
      "Epoch 192/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2628 - val_loss: 0.5042\n",
      "Epoch 193/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2166 - val_loss: 0.5482\n",
      "Epoch 194/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2184 - val_loss: 0.5168\n",
      "Epoch 195/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2014 - val_loss: 0.5952\n",
      "Epoch 196/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2956 - val_loss: 0.5725\n",
      "Epoch 197/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1658 - val_loss: 0.4595\n",
      "Epoch 198/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2751 - val_loss: 0.4670\n",
      "Epoch 199/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1665 - val_loss: 0.5118\n",
      "Epoch 200/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3220 - val_loss: 0.4820\n",
      "Epoch 201/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2064 - val_loss: 0.5042\n",
      "Epoch 202/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2076 - val_loss: 0.5582\n",
      "Epoch 203/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2097 - val_loss: 0.6672\n",
      "Epoch 204/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2973 - val_loss: 0.6592\n",
      "Epoch 205/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1934 - val_loss: 0.5708\n",
      "Epoch 206/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2143 - val_loss: 0.5036\n",
      "Epoch 207/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3551 - val_loss: 0.7478\n",
      "Epoch 208/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2133 - val_loss: 0.5771\n",
      "Epoch 209/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2374 - val_loss: 0.5237\n",
      "Epoch 210/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2346 - val_loss: 0.5754\n",
      "Epoch 211/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2562 - val_loss: 1.0034\n",
      "Epoch 212/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2252 - val_loss: 0.6481\n",
      "Epoch 213/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2424 - val_loss: 0.6478\n",
      "Epoch 214/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3020 - val_loss: 0.6460\n",
      "Epoch 215/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2320 - val_loss: 0.5193\n",
      "Epoch 216/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2458 - val_loss: 0.6312\n",
      "Epoch 217/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1792 - val_loss: 0.6537\n",
      "Epoch 218/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2206 - val_loss: 0.8086\n",
      "Epoch 219/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2167 - val_loss: 0.7441\n",
      "Epoch 220/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2077 - val_loss: 0.5220\n",
      "Epoch 221/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2167 - val_loss: 0.7420\n",
      "Epoch 222/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2825 - val_loss: 0.7273\n",
      "Epoch 223/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2035 - val_loss: 0.5725\n",
      "Epoch 224/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1738 - val_loss: 0.8218\n",
      "Epoch 225/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1568 - val_loss: 0.7565\n",
      "Epoch 226/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1840 - val_loss: 0.7374\n",
      "Epoch 227/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2239 - val_loss: 0.7242\n",
      "Epoch 228/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2594 - val_loss: 0.7396\n",
      "Epoch 229/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1601 - val_loss: 0.6420\n",
      "Epoch 230/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2561 - val_loss: 0.6538\n",
      "Epoch 231/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1694 - val_loss: 0.7893\n",
      "Epoch 232/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2358 - val_loss: 0.6917\n",
      "Epoch 233/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2120 - val_loss: 0.7475\n",
      "Epoch 234/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1342 - val_loss: 0.5608\n",
      "Epoch 235/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1868 - val_loss: 0.5740\n",
      "Epoch 236/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2020 - val_loss: 0.7942\n",
      "Epoch 237/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2450 - val_loss: 0.6481\n",
      "Epoch 238/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2046 - val_loss: 0.7739\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2461 - val_loss: 0.6440\n",
      "Epoch 240/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1781 - val_loss: 0.5827\n",
      "Epoch 241/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2351 - val_loss: 0.8121\n",
      "Epoch 242/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2184 - val_loss: 0.5549\n",
      "Epoch 243/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1656 - val_loss: 0.5600\n",
      "Epoch 244/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2260 - val_loss: 0.6065\n",
      "Epoch 245/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1813 - val_loss: 0.6773\n",
      "Epoch 246/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1714 - val_loss: 0.6227\n",
      "Epoch 247/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2938 - val_loss: 0.6944\n",
      "Epoch 248/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1933 - val_loss: 0.6560\n",
      "Epoch 249/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1855 - val_loss: 0.6149\n",
      "Epoch 250/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2067 - val_loss: 0.5231\n",
      "Epoch 251/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2163 - val_loss: 0.4999\n",
      "Epoch 252/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2256 - val_loss: 0.5564\n",
      "Epoch 253/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1999 - val_loss: 0.5278\n",
      "Epoch 254/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2010 - val_loss: 0.5027\n",
      "Epoch 255/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2016 - val_loss: 0.5083\n",
      "Epoch 256/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1345 - val_loss: 0.5606\n",
      "Epoch 257/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1495 - val_loss: 0.4761\n",
      "Epoch 258/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2587 - val_loss: 0.6178\n",
      "Epoch 259/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1491 - val_loss: 0.6059\n",
      "Epoch 260/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2958 - val_loss: 0.7125\n",
      "Epoch 261/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1555 - val_loss: 0.8530\n",
      "Epoch 262/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1922 - val_loss: 0.6350\n",
      "Epoch 263/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1348 - val_loss: 0.6229\n",
      "Epoch 264/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2671 - val_loss: 0.6036\n",
      "Epoch 265/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1668 - val_loss: 0.6402\n",
      "Epoch 266/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1823 - val_loss: 0.5994\n",
      "Epoch 267/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1838 - val_loss: 0.7509\n",
      "Epoch 268/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2066 - val_loss: 0.6234\n",
      "Epoch 269/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1708 - val_loss: 0.5801\n",
      "Epoch 270/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1499 - val_loss: 0.4936\n",
      "Epoch 271/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1428 - val_loss: 0.6006\n",
      "Epoch 272/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1528 - val_loss: 0.5706\n",
      "Epoch 273/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1854 - val_loss: 0.6750\n",
      "Epoch 274/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1426 - val_loss: 0.8999\n",
      "Epoch 275/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1832 - val_loss: 0.6465\n",
      "Epoch 276/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1227 - val_loss: 0.6262\n",
      "Epoch 277/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1389 - val_loss: 0.6182\n",
      "Epoch 278/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1391 - val_loss: 0.5661\n",
      "Epoch 279/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1432 - val_loss: 0.6048\n",
      "Epoch 280/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1751 - val_loss: 0.6444\n",
      "Epoch 281/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2070 - val_loss: 0.6125\n",
      "Epoch 282/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1943 - val_loss: 0.7058\n",
      "Epoch 283/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1838 - val_loss: 0.6874\n",
      "Epoch 284/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1508 - val_loss: 0.6816\n",
      "Epoch 285/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1732 - val_loss: 0.6379\n",
      "Epoch 286/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2918 - val_loss: 0.8229\n",
      "Epoch 287/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1603 - val_loss: 0.5710\n",
      "Epoch 288/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1702 - val_loss: 0.7282\n",
      "Epoch 289/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1412 - val_loss: 0.5905\n",
      "Epoch 290/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1578 - val_loss: 0.6127\n",
      "Epoch 291/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2019 - val_loss: 0.4766\n",
      "Epoch 292/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1470 - val_loss: 0.5392\n",
      "Epoch 293/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1502 - val_loss: 0.5845\n",
      "Epoch 294/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1339 - val_loss: 0.5782\n",
      "Epoch 295/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1212 - val_loss: 0.5685\n",
      "Epoch 296/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1554 - val_loss: 0.4726\n",
      "Epoch 297/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1623 - val_loss: 0.6177\n",
      "Epoch 298/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2180 - val_loss: 0.4462\n",
      "Epoch 299/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1931 - val_loss: 0.6783\n",
      "Epoch 300/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2158 - val_loss: 0.6624\n",
      "Epoch 301/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2072 - val_loss: 0.7855\n",
      "Epoch 302/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1652 - val_loss: 0.5652\n",
      "Epoch 303/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1544 - val_loss: 0.5164\n",
      "Epoch 304/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1341 - val_loss: 0.4532\n",
      "Epoch 305/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1738 - val_loss: 0.5742\n",
      "Epoch 306/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1144 - val_loss: 0.6477\n",
      "Epoch 307/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1646 - val_loss: 0.5014\n",
      "Epoch 308/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.3187 - val_loss: 0.5135\n",
      "Epoch 309/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2138 - val_loss: 0.5156\n",
      "Epoch 310/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2087 - val_loss: 0.5865\n",
      "Epoch 311/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1236 - val_loss: 0.6076\n",
      "Epoch 312/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1697 - val_loss: 0.5619\n",
      "Epoch 313/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1563 - val_loss: 0.5767\n",
      "Epoch 314/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1343 - val_loss: 0.4839\n",
      "Epoch 315/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1616 - val_loss: 0.4809\n",
      "Epoch 316/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1259 - val_loss: 0.4469\n",
      "Epoch 317/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1809 - val_loss: 0.5631\n",
      "Epoch 318/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1779 - val_loss: 0.6288\n",
      "Epoch 319/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1628 - val_loss: 0.5534\n",
      "Epoch 320/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1238 - val_loss: 0.6154\n",
      "Epoch 321/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1212 - val_loss: 0.5413\n",
      "Epoch 322/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1297 - val_loss: 0.5229\n",
      "Epoch 323/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1265 - val_loss: 0.4994\n",
      "Epoch 324/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1472 - val_loss: 0.6189\n",
      "Epoch 325/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1232 - val_loss: 0.5727\n",
      "Epoch 326/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1136 - val_loss: 0.5575\n",
      "Epoch 327/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1163 - val_loss: 0.5819\n",
      "Epoch 328/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1420 - val_loss: 0.5844\n",
      "Epoch 329/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1328 - val_loss: 0.5229\n",
      "Epoch 330/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1599 - val_loss: 0.6079\n",
      "Epoch 331/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1253 - val_loss: 0.6213\n",
      "Epoch 332/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1522 - val_loss: 0.6402\n",
      "Epoch 333/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1176 - val_loss: 0.5661\n",
      "Epoch 334/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1254 - val_loss: 0.6173\n",
      "Epoch 335/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1164 - val_loss: 0.6792\n",
      "Epoch 336/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1171 - val_loss: 0.4955\n",
      "Epoch 337/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.2285 - val_loss: 0.6441\n",
      "Epoch 338/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1588 - val_loss: 0.6615\n",
      "Epoch 339/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1661 - val_loss: 0.6742\n",
      "Epoch 340/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1378 - val_loss: 0.6558\n",
      "Epoch 341/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1389 - val_loss: 0.6930\n",
      "Epoch 342/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1261 - val_loss: 0.6282\n",
      "Epoch 343/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1236 - val_loss: 0.6160\n",
      "Epoch 344/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1340 - val_loss: 0.5947\n",
      "Epoch 345/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1129 - val_loss: 0.6696\n",
      "Epoch 346/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1215 - val_loss: 0.5275\n",
      "Epoch 347/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1187 - val_loss: 0.5646\n",
      "Epoch 348/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1808 - val_loss: 0.9133\n",
      "Epoch 349/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1509 - val_loss: 0.8959\n",
      "Epoch 350/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1299 - val_loss: 0.6403\n",
      "Epoch 351/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1243 - val_loss: 0.6458\n",
      "Epoch 352/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1373 - val_loss: 0.5505\n",
      "Epoch 353/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2043 - val_loss: 0.7107\n",
      "Epoch 354/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1752 - val_loss: 0.7983\n",
      "Epoch 355/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1256 - val_loss: 0.5711\n",
      "Epoch 356/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2396 - val_loss: 0.5753\n",
      "Epoch 357/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1701 - val_loss: 0.6237\n",
      "Epoch 358/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1812 - val_loss: 0.8367\n",
      "Epoch 359/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1769 - val_loss: 0.7561\n",
      "Epoch 360/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1151 - val_loss: 0.5986\n",
      "Epoch 361/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1628 - val_loss: 0.5608\n",
      "Epoch 362/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1295 - val_loss: 0.4817\n",
      "Epoch 363/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1438 - val_loss: 0.5418\n",
      "Epoch 364/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1333 - val_loss: 0.5265\n",
      "Epoch 365/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1706 - val_loss: 0.6164\n",
      "Epoch 366/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1795 - val_loss: 0.5296\n",
      "Epoch 367/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1687 - val_loss: 0.6418\n",
      "Epoch 368/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1297 - val_loss: 0.6456\n",
      "Epoch 369/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1100 - val_loss: 0.6336\n",
      "Epoch 370/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1241 - val_loss: 0.5947\n",
      "Epoch 371/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1111 - val_loss: 0.5735\n",
      "Epoch 372/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1591 - val_loss: 0.6909\n",
      "Epoch 373/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1215 - val_loss: 0.7089\n",
      "Epoch 374/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1507 - val_loss: 0.6002\n",
      "Epoch 375/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1362 - val_loss: 0.7307\n",
      "Epoch 376/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1383 - val_loss: 0.8209\n",
      "Epoch 377/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1390 - val_loss: 0.5504\n",
      "Epoch 378/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2372 - val_loss: 0.5619\n",
      "Epoch 379/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1209 - val_loss: 0.8996\n",
      "Epoch 380/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1308 - val_loss: 0.6456\n",
      "Epoch 381/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1292 - val_loss: 0.7453\n",
      "Epoch 382/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1785 - val_loss: 0.6964\n",
      "Epoch 383/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1985 - val_loss: 0.6586\n",
      "Epoch 384/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1436 - val_loss: 0.6904\n",
      "Epoch 385/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1561 - val_loss: 0.6735\n",
      "Epoch 386/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1669 - val_loss: 0.6013\n",
      "Epoch 387/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1263 - val_loss: 0.7305\n",
      "Epoch 388/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1248 - val_loss: 0.6117\n",
      "Epoch 389/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1235 - val_loss: 0.7940\n",
      "Epoch 390/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1347 - val_loss: 0.6266\n",
      "Epoch 391/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1316 - val_loss: 0.5063\n",
      "Epoch 392/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1401 - val_loss: 0.6238\n",
      "Epoch 393/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1162 - val_loss: 0.5878\n",
      "Epoch 394/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1438 - val_loss: 0.5821\n",
      "Epoch 395/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1177 - val_loss: 0.6551\n",
      "Epoch 396/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1467 - val_loss: 0.5476\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1059 - val_loss: 0.6187\n",
      "Epoch 398/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1040 - val_loss: 0.6751\n",
      "Epoch 399/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1518 - val_loss: 0.5435\n",
      "Epoch 400/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1832 - val_loss: 0.7521\n",
      "Epoch 401/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.5956\n",
      "Epoch 402/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1302 - val_loss: 0.5667\n",
      "Epoch 403/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1430 - val_loss: 0.5809\n",
      "Epoch 404/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1223 - val_loss: 0.4832\n",
      "Epoch 405/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1083 - val_loss: 0.6229\n",
      "Epoch 406/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1510 - val_loss: 0.5259\n",
      "Epoch 407/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1191 - val_loss: 0.6286\n",
      "Epoch 408/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1818 - val_loss: 0.6043\n",
      "Epoch 409/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1105 - val_loss: 0.6068\n",
      "Epoch 410/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0756 - val_loss: 0.5922\n",
      "Epoch 411/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1145 - val_loss: 0.5889\n",
      "Epoch 412/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0943 - val_loss: 0.6655\n",
      "Epoch 413/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0980 - val_loss: 0.6287\n",
      "Epoch 414/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1032 - val_loss: 0.6089\n",
      "Epoch 415/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1220 - val_loss: 0.4780\n",
      "Epoch 416/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0974 - val_loss: 0.5121\n",
      "Epoch 417/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0964 - val_loss: 0.6008\n",
      "Epoch 418/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1176 - val_loss: 0.5235\n",
      "Epoch 419/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1046 - val_loss: 0.5809\n",
      "Epoch 420/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1104 - val_loss: 0.4968\n",
      "Epoch 421/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0967 - val_loss: 0.5375\n",
      "Epoch 422/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0821 - val_loss: 0.5604\n",
      "Epoch 423/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1012 - val_loss: 0.6549\n",
      "Epoch 424/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1089 - val_loss: 0.5595\n",
      "Epoch 425/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0926 - val_loss: 0.6318\n",
      "Epoch 426/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1289 - val_loss: 0.6661\n",
      "Epoch 427/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1260 - val_loss: 0.5620\n",
      "Epoch 428/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1084 - val_loss: 0.5841\n",
      "Epoch 429/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1304 - val_loss: 0.5453\n",
      "Epoch 430/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1432 - val_loss: 0.6602\n",
      "Epoch 431/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1280 - val_loss: 0.5530\n",
      "Epoch 432/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1038 - val_loss: 0.5763\n",
      "Epoch 433/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0981 - val_loss: 0.6394\n",
      "Epoch 434/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1595 - val_loss: 0.5676\n",
      "Epoch 435/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1229 - val_loss: 0.6110\n",
      "Epoch 436/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0947 - val_loss: 0.6470\n",
      "Epoch 437/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1231 - val_loss: 0.5053\n",
      "Epoch 438/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0944 - val_loss: 0.4836\n",
      "Epoch 439/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0968 - val_loss: 0.6045\n",
      "Epoch 440/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1220 - val_loss: 0.7966\n",
      "Epoch 441/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0947 - val_loss: 0.6649\n",
      "Epoch 442/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1141 - val_loss: 0.4934\n",
      "Epoch 443/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1068 - val_loss: 0.5858\n",
      "Epoch 444/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1116 - val_loss: 0.6193\n",
      "Epoch 445/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1244 - val_loss: 0.6022\n",
      "Epoch 446/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1008 - val_loss: 0.6131\n",
      "Epoch 447/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1473 - val_loss: 0.5238\n",
      "Epoch 448/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2146 - val_loss: 0.5920\n",
      "Epoch 449/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1669 - val_loss: 0.9697\n",
      "Epoch 450/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0940 - val_loss: 0.7415\n",
      "Epoch 451/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0970 - val_loss: 0.6532\n",
      "Epoch 452/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.0868 - val_loss: 0.5792\n",
      "Epoch 453/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1546 - val_loss: 0.5689\n",
      "Epoch 454/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1636 - val_loss: 0.6748\n",
      "Epoch 455/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1382 - val_loss: 0.6670\n",
      "Epoch 456/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1352 - val_loss: 0.5232\n",
      "Epoch 457/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1876 - val_loss: 0.7670\n",
      "Epoch 458/500\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.1828 - val_loss: 0.5281\n",
      "Epoch 459/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0848 - val_loss: 0.5686\n",
      "Epoch 460/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0939 - val_loss: 0.5619\n",
      "Epoch 461/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0950 - val_loss: 0.5060\n",
      "Epoch 462/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0934 - val_loss: 0.5836\n",
      "Epoch 463/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0879 - val_loss: 0.6957\n",
      "Epoch 464/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1914 - val_loss: 0.5992\n",
      "Epoch 465/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1089 - val_loss: 0.5487\n",
      "Epoch 466/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1763 - val_loss: 1.0589\n",
      "Epoch 467/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2025 - val_loss: 0.5165\n",
      "Epoch 468/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1385 - val_loss: 0.7100\n",
      "Epoch 469/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1137 - val_loss: 0.6766\n",
      "Epoch 470/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1066 - val_loss: 0.6758\n",
      "Epoch 471/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0715 - val_loss: 0.6634\n",
      "Epoch 472/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0946 - val_loss: 0.5889\n",
      "Epoch 473/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1258 - val_loss: 0.5657\n",
      "Epoch 474/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0960 - val_loss: 0.5956\n",
      "Epoch 475/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1133 - val_loss: 0.5763\n",
      "Epoch 476/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0844 - val_loss: 0.6625\n",
      "Epoch 477/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0807 - val_loss: 0.5600\n",
      "Epoch 478/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0986 - val_loss: 0.6606\n",
      "Epoch 479/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0803 - val_loss: 0.6810\n",
      "Epoch 480/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0914 - val_loss: 0.6961\n",
      "Epoch 481/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0881 - val_loss: 0.7204\n",
      "Epoch 482/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0857 - val_loss: 0.7176\n",
      "Epoch 483/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0905 - val_loss: 0.6921\n",
      "Epoch 484/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0965 - val_loss: 0.6824\n",
      "Epoch 485/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0786 - val_loss: 0.7383\n",
      "Epoch 486/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1182 - val_loss: 0.5953\n",
      "Epoch 487/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0834 - val_loss: 0.6803\n",
      "Epoch 488/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0754 - val_loss: 0.6188\n",
      "Epoch 489/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1171 - val_loss: 0.7030\n",
      "Epoch 490/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0814 - val_loss: 0.6728\n",
      "Epoch 491/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1042 - val_loss: 0.6922\n",
      "Epoch 492/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0973 - val_loss: 0.6005\n",
      "Epoch 493/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1013 - val_loss: 0.6037\n",
      "Epoch 494/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1698 - val_loss: 0.5348\n",
      "Epoch 495/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1101 - val_loss: 0.6015\n",
      "Epoch 496/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1027 - val_loss: 0.5242\n",
      "Epoch 497/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0909 - val_loss: 0.5821\n",
      "Epoch 498/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0760 - val_loss: 0.6081\n",
      "Epoch 499/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.0833 - val_loss: 0.5463\n",
      "Epoch 500/500\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1947 - val_loss: 0.5700\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 24, 12)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 24, 24)       1800        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "seq_self_attention_3 (SeqSelfAt (None, 24, 24)       577         bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 24, 24)       0           seq_self_attention_3[0][0]       \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 24, 24)       48          add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 12)           6924        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 12)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 588)          0           dropout_3[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            589         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            2           dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 9,940\n",
      "Trainable params: 9,940\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Predict time:  0.30213451385498047\n",
      "RMSE:  6.505646323782301\n",
      "RMSE2:  4.298012888589038\n",
      "MAE:  4.124935684601466\n",
      "MAE2:  4.124935684601466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse score')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "opt = optimizers.Adam(lr=0.001,decay = 0.0001)\n",
    "print('Train...')\n",
    "# model.compile(optimizer = opt , loss=\"mse\")\n",
    "model.compile(optimizer = \"adam\" , loss=\"mse\")\n",
    "history = model.fit([x_train,x_train], y_train, epochs = 500, batch_size=8, validation_split=0.1, shuffle=True)\n",
    "# history = model.fit(x_train, y_train, epochs = 500, batch_size=6, validation_split=0.1, shuffle=True)\n",
    "model.summary()\n",
    "#Save Model\n",
    "model.save('GRU_Single_Attention_model_Doric.h5')  # creates a HDF5 file \n",
    "del model\n",
    "\n",
    "custom_ob = {'LayerNormalization': LayerNormalization , 'SeqSelfAttention':SeqSelfAttention}\n",
    "model = load_model('GRU_Single_Attention_model_Doric.h5', custom_objects=custom_ob)\n",
    "t1 = time.time()\n",
    "# y_pred = model.predict([x_test,x_test])\n",
    "y_pred2 = model.predict(x_test)\n",
    "y_pred = model.predict(x_train)\n",
    "t2 = time.time()\n",
    "print('Predict time: ',t2-t1)\n",
    "y_pred = scaler.inverse_transform(y_pred)#Undo scaling\n",
    "rmse_lstm2 = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print('RMSE: ',rmse_lstm)\n",
    "print('RMSE2: ',rmse_lstm2)\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('MAE: ',mae)\n",
    "print('MAE2: ',mae)\n",
    "# r22 =  r2_score(y_test, y_pred2)\n",
    "# r2 =  r2_score(y_train, y_pred)\n",
    "# print('R-square: ',r2)\n",
    "# print('R-square2: ',r22)\n",
    "\n",
    "# n = len(y_test)\n",
    "# p = 12\n",
    "# Adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "# Adj_r22 = 1-(1-r22)*(n-1)/(n-p-1)\n",
    "# print('Adj R-square: ',Adj_r2)\n",
    "# print('Adj R-square2: ',Adj_r22)\n",
    "\n",
    "plt.plot(history.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"No. Of Epochs\")\n",
    "plt.ylabel(\"mse score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ec71ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 108 samples, validate on 12 samples\n",
      "Epoch 1/200\n",
      "108/108 [==============================] - 3s 23ms/step - loss: 2.7394 - val_loss: 1.8436\n",
      "Epoch 2/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.6984 - val_loss: 1.7712\n",
      "Epoch 3/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.6187 - val_loss: 1.7008\n",
      "Epoch 4/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.5490 - val_loss: 1.6388\n",
      "Epoch 5/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.4812 - val_loss: 1.5772\n",
      "Epoch 6/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.4285 - val_loss: 1.5203\n",
      "Epoch 7/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.3192 - val_loss: 1.4664\n",
      "Epoch 8/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.2936 - val_loss: 1.4280\n",
      "Epoch 9/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.1580 - val_loss: 1.3946\n",
      "Epoch 10/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 2.1407 - val_loss: 1.3701\n",
      "Epoch 11/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 2.0958 - val_loss: 1.3453\n",
      "Epoch 12/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 2.0984 - val_loss: 1.3250\n",
      "Epoch 13/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 2.0175 - val_loss: 1.3061\n",
      "Epoch 14/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.9780 - val_loss: 1.2800\n",
      "Epoch 15/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.9640 - val_loss: 1.2510\n",
      "Epoch 16/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.9403 - val_loss: 1.2281\n",
      "Epoch 17/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.9083 - val_loss: 1.2214\n",
      "Epoch 18/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.8386 - val_loss: 1.2009\n",
      "Epoch 19/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.8570 - val_loss: 1.1810\n",
      "Epoch 20/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.8542 - val_loss: 1.1556\n",
      "Epoch 21/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.8189 - val_loss: 1.1266\n",
      "Epoch 22/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.8151 - val_loss: 1.1117\n",
      "Epoch 23/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.8048 - val_loss: 1.1152\n",
      "Epoch 24/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.7737 - val_loss: 1.0920\n",
      "Epoch 25/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.6903 - val_loss: 1.0597\n",
      "Epoch 26/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.6681 - val_loss: 1.0522\n",
      "Epoch 27/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.6842 - val_loss: 1.0231\n",
      "Epoch 28/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.7125 - val_loss: 1.0044\n",
      "Epoch 29/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.6248 - val_loss: 0.9992\n",
      "Epoch 30/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.6432 - val_loss: 0.9812\n",
      "Epoch 31/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 1.6484 - val_loss: 0.9776\n",
      "Epoch 32/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 1.7026 - val_loss: 0.9662\n",
      "Epoch 33/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.6533 - val_loss: 0.9634\n",
      "Epoch 34/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 1.5904 - val_loss: 0.9448\n",
      "Epoch 35/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.5539 - val_loss: 0.9407\n",
      "Epoch 36/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.5709 - val_loss: 0.9349\n",
      "Epoch 37/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.6026 - val_loss: 0.9222\n",
      "Epoch 38/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.5798 - val_loss: 0.9168\n",
      "Epoch 39/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.5047 - val_loss: 0.9166\n",
      "Epoch 40/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.5185 - val_loss: 0.9195\n",
      "Epoch 41/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.5778 - val_loss: 0.9040\n",
      "Epoch 42/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.5352 - val_loss: 0.9124\n",
      "Epoch 43/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.5337 - val_loss: 0.8974\n",
      "Epoch 44/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4737 - val_loss: 0.9138\n",
      "Epoch 45/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4810 - val_loss: 0.8817\n",
      "Epoch 46/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.4823 - val_loss: 0.8971\n",
      "Epoch 47/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.5015 - val_loss: 0.8643\n",
      "Epoch 48/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.4451 - val_loss: 0.8632\n",
      "Epoch 49/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4212 - val_loss: 0.8453\n",
      "Epoch 50/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.5141 - val_loss: 0.8506\n",
      "Epoch 51/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4394 - val_loss: 0.8406\n",
      "Epoch 52/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4516 - val_loss: 0.8348\n",
      "Epoch 53/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.5043 - val_loss: 0.8560\n",
      "Epoch 54/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4454 - val_loss: 0.8359\n",
      "Epoch 55/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4148 - val_loss: 0.8198\n",
      "Epoch 56/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.4313 - val_loss: 0.8256\n",
      "Epoch 57/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.3990 - val_loss: 0.7967\n",
      "Epoch 58/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.3587 - val_loss: 0.7894\n",
      "Epoch 59/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.3987 - val_loss: 0.7737\n",
      "Epoch 60/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.3745 - val_loss: 0.7784\n",
      "Epoch 61/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.2856 - val_loss: 0.7855\n",
      "Epoch 62/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.2228 - val_loss: 0.7694\n",
      "Epoch 63/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.3023 - val_loss: 0.7528\n",
      "Epoch 64/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.2916 - val_loss: 0.7499\n",
      "Epoch 65/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.2070 - val_loss: 0.7229\n",
      "Epoch 66/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.1992 - val_loss: 0.7574\n",
      "Epoch 67/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.1471 - val_loss: 0.7303\n",
      "Epoch 68/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.2056 - val_loss: 0.7324\n",
      "Epoch 69/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.1616 - val_loss: 0.6477\n",
      "Epoch 70/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.2152 - val_loss: 0.6273\n",
      "Epoch 71/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.1989 - val_loss: 0.6041\n",
      "Epoch 72/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.1454 - val_loss: 0.5969\n",
      "Epoch 73/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.0913 - val_loss: 0.6441\n",
      "Epoch 74/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.0541 - val_loss: 0.6010\n",
      "Epoch 75/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.1023 - val_loss: 0.5508\n",
      "Epoch 76/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.0389 - val_loss: 0.5478\n",
      "Epoch 77/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.0589 - val_loss: 0.5304\n",
      "Epoch 78/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.0195 - val_loss: 0.5278\n",
      "Epoch 79/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.9686 - val_loss: 0.8107\n",
      "Epoch 80/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 1.0000 - val_loss: 0.7046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8749 - val_loss: 0.5534\n",
      "Epoch 82/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.9435 - val_loss: 0.5315\n",
      "Epoch 83/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9955 - val_loss: 0.5730\n",
      "Epoch 84/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8151 - val_loss: 0.6745\n",
      "Epoch 85/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8505 - val_loss: 0.4897\n",
      "Epoch 86/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8584 - val_loss: 0.9878\n",
      "Epoch 87/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8404 - val_loss: 0.6621\n",
      "Epoch 88/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.9655 - val_loss: 0.4950\n",
      "Epoch 89/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8280 - val_loss: 0.5456\n",
      "Epoch 90/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8352 - val_loss: 0.6379\n",
      "Epoch 91/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7992 - val_loss: 1.2197\n",
      "Epoch 92/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8855 - val_loss: 0.6315\n",
      "Epoch 93/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7606 - val_loss: 0.6358\n",
      "Epoch 94/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7585 - val_loss: 0.6252\n",
      "Epoch 95/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7873 - val_loss: 0.9524\n",
      "Epoch 96/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.8206 - val_loss: 0.5836\n",
      "Epoch 97/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7008 - val_loss: 0.4429\n",
      "Epoch 98/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7467 - val_loss: 0.6083\n",
      "Epoch 99/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7456 - val_loss: 1.0932\n",
      "Epoch 100/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8129 - val_loss: 1.3479\n",
      "Epoch 101/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7028 - val_loss: 0.8431\n",
      "Epoch 102/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6098 - val_loss: 0.4569\n",
      "Epoch 103/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7884 - val_loss: 1.3929\n",
      "Epoch 104/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7815 - val_loss: 0.6596\n",
      "Epoch 105/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7726 - val_loss: 0.5268\n",
      "Epoch 106/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7537 - val_loss: 0.7128\n",
      "Epoch 107/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8150 - val_loss: 0.5095\n",
      "Epoch 108/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6804 - val_loss: 1.0148\n",
      "Epoch 109/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7988 - val_loss: 0.4889\n",
      "Epoch 110/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7144 - val_loss: 0.4274\n",
      "Epoch 111/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7128 - val_loss: 0.9777\n",
      "Epoch 112/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7717 - val_loss: 0.7793\n",
      "Epoch 113/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8006 - val_loss: 1.0336\n",
      "Epoch 114/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7736 - val_loss: 1.6028\n",
      "Epoch 115/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7832 - val_loss: 0.5728\n",
      "Epoch 116/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7269 - val_loss: 0.4359\n",
      "Epoch 117/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6440 - val_loss: 0.5496\n",
      "Epoch 118/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7346 - val_loss: 0.4363\n",
      "Epoch 119/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5794 - val_loss: 1.3371\n",
      "Epoch 120/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7664 - val_loss: 0.9002\n",
      "Epoch 121/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7736 - val_loss: 0.4307\n",
      "Epoch 122/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8142 - val_loss: 0.4745\n",
      "Epoch 123/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7864 - val_loss: 0.5360\n",
      "Epoch 124/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6871 - val_loss: 0.5252\n",
      "Epoch 125/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7307 - val_loss: 0.5252\n",
      "Epoch 126/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7564 - val_loss: 0.4156\n",
      "Epoch 127/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7160 - val_loss: 0.4688\n",
      "Epoch 128/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6487 - val_loss: 0.5061\n",
      "Epoch 129/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.8046 - val_loss: 0.4136\n",
      "Epoch 130/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6561 - val_loss: 0.8256\n",
      "Epoch 131/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6864 - val_loss: 0.4251\n",
      "Epoch 132/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7502 - val_loss: 0.4445\n",
      "Epoch 133/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7083 - val_loss: 0.4188\n",
      "Epoch 134/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6612 - val_loss: 0.4307\n",
      "Epoch 135/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6873 - val_loss: 0.4308\n",
      "Epoch 136/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6158 - val_loss: 0.4022\n",
      "Epoch 137/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6208 - val_loss: 0.6778\n",
      "Epoch 138/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6304 - val_loss: 0.3927\n",
      "Epoch 139/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6073 - val_loss: 0.4520\n",
      "Epoch 140/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6675 - val_loss: 0.8047\n",
      "Epoch 141/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6355 - val_loss: 0.4488\n",
      "Epoch 142/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6456 - val_loss: 0.4890\n",
      "Epoch 143/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6074 - val_loss: 0.5632\n",
      "Epoch 144/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6697 - val_loss: 0.5189\n",
      "Epoch 145/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6779 - val_loss: 0.5666\n",
      "Epoch 146/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6750 - val_loss: 0.6503\n",
      "Epoch 147/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5801 - val_loss: 0.4318\n",
      "Epoch 148/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6086 - val_loss: 0.4964\n",
      "Epoch 149/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7168 - val_loss: 0.5047\n",
      "Epoch 150/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6572 - val_loss: 0.4702\n",
      "Epoch 151/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5477 - val_loss: 1.5302\n",
      "Epoch 152/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7156 - val_loss: 0.4230\n",
      "Epoch 153/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6370 - val_loss: 0.7630\n",
      "Epoch 154/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5945 - val_loss: 0.5344\n",
      "Epoch 155/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5186 - val_loss: 0.4639\n",
      "Epoch 156/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6038 - val_loss: 0.4388\n",
      "Epoch 157/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5622 - val_loss: 0.4214\n",
      "Epoch 158/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7108 - val_loss: 0.4139\n",
      "Epoch 159/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5564 - val_loss: 0.5346\n",
      "Epoch 160/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6157 - val_loss: 0.4211\n",
      "Epoch 161/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6361 - val_loss: 0.4619\n",
      "Epoch 162/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6169 - val_loss: 0.5299\n",
      "Epoch 163/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6248 - val_loss: 0.5139\n",
      "Epoch 164/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6093 - val_loss: 0.4050\n",
      "Epoch 165/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6271 - val_loss: 0.5283\n",
      "Epoch 166/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7082 - val_loss: 0.4220\n",
      "Epoch 167/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6187 - val_loss: 0.4414\n",
      "Epoch 168/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6402 - val_loss: 0.7495\n",
      "Epoch 169/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.7090 - val_loss: 0.4028\n",
      "Epoch 170/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6302 - val_loss: 0.5133\n",
      "Epoch 171/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6111 - val_loss: 0.4651\n",
      "Epoch 172/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5815 - val_loss: 0.4035\n",
      "Epoch 173/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6751 - val_loss: 0.3999\n",
      "Epoch 174/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5900 - val_loss: 0.4248\n",
      "Epoch 175/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6339 - val_loss: 0.4416\n",
      "Epoch 176/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6737 - val_loss: 0.4475\n",
      "Epoch 177/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5359 - val_loss: 0.6570\n",
      "Epoch 178/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6169 - val_loss: 0.4630\n",
      "Epoch 179/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.5974 - val_loss: 0.7045\n",
      "Epoch 180/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6567 - val_loss: 0.4240\n",
      "Epoch 181/200\n",
      "108/108 [==============================] - 1s 6ms/step - loss: 0.6329 - val_loss: 0.5410\n",
      "Epoch 182/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5074 - val_loss: 0.4030\n",
      "Epoch 183/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5401 - val_loss: 0.4550\n",
      "Epoch 184/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6879 - val_loss: 0.4008\n",
      "Epoch 185/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5158 - val_loss: 0.4765\n",
      "Epoch 186/200\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5814 - val_loss: 0.4603\n",
      "Epoch 187/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7015 - val_loss: 0.5040\n",
      "Epoch 188/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5885 - val_loss: 0.4232\n",
      "Epoch 189/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4973 - val_loss: 0.4282\n",
      "Epoch 190/200\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.6131 - val_loss: 0.4322\n",
      "Epoch 191/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5841 - val_loss: 0.4609\n",
      "Epoch 192/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5410 - val_loss: 0.4161\n",
      "Epoch 193/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5860 - val_loss: 0.6244\n",
      "Epoch 194/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5693 - val_loss: 0.4732\n",
      "Epoch 195/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6382 - val_loss: 0.4238\n",
      "Epoch 196/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6333 - val_loss: 0.4769\n",
      "Epoch 197/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5984 - val_loss: 0.3999\n",
      "Epoch 198/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5977 - val_loss: 0.4176\n",
      "Epoch 199/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5012 - val_loss: 0.5338\n",
      "Epoch 200/200\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6104 - val_loss: 0.5149\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_8 (Bidirection (None, 24, 12)            684       \n",
      "_________________________________________________________________\n",
      "layer_normalization_6 (Layer (None, 24, 12)            24        \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 12)                684       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 1,405\n",
      "Trainable params: 1,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Saved\n",
      "Predict time:  0.357043981552124\n",
      "RMSE:  5.066496104427424\n",
      "RMSE2:  4.774075712426358\n",
      "MAE:  3.8027951530615494\n",
      "MAE2:  3.8027951530615494\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'mse score')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "init = glorot_normal(seed=None) # 給 LSTM\n",
    "init_d = RandomUniform(minval=-0.05, maxval=0.05) # 給 Dense layer\n",
    "nadam = optimizers.Nadam(lr=0.0015,clipvalue=0.5)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(6, kernel_initializer=init ,return_sequences = True,kernel_regularizer=regularizers.l2(0.01)\n",
    "                             ,recurrent_regularizer = regularizers.l2(0.01) ,input_shape=(x_train.shape[1],x_train.shape[2]))))\n",
    "model.add(LayerNormalization())\n",
    "model.add(Bidirectional(GRU(6,kernel_initializer=init,kernel_regularizer=regularizers.l2(0.01),recurrent_regularizer = regularizers.l2(0.01))))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units=1, kernel_initializer=init_d))\n",
    "model.compile(optimizer = nadam , loss=\"mse\")\n",
    "history = model.fit(x_train, y_train, epochs=200, batch_size=24, validation_split=0.1, shuffle=True)\n",
    "#model summary\n",
    "model.summary()\n",
    "#Save Model\n",
    "model.save('GRU_model_doric.h5')  # creates a HDF5 file \n",
    "print('Model Saved')\n",
    "del model  # deletes the existing model\n",
    "\n",
    "custom_ob = {'LayerNormalization': LayerNormalization , 'SeqSelfAttention':SeqSelfAttention}\n",
    "model = load_model('GRU_model_doric.h5', custom_objects=custom_ob)\n",
    "t1 = time.time()\n",
    "# y_pred = model.predict([x_test,x_test])\n",
    "y_pred2 = model.predict(x_test)\n",
    "y_pred = model.predict(x_train)\n",
    "t2 = time.time()\n",
    "print('Predict time: ',t2-t1)\n",
    "y_pred = scaler.inverse_transform(y_pred)#Undo scaling\n",
    "rmse_lstm2 = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print('RMSE: ',rmse_lstm)\n",
    "print('RMSE2: ',rmse_lstm2)\n",
    "mae = mean_absolute_error(y_test, y_pred2)\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "print('MAE: ',mae)\n",
    "print('MAE2: ',mae)\n",
    "# r22 =  r2_score(y_test, y_pred2)\n",
    "# r2 =  r2_score(y_train, y_pred)\n",
    "# print('R-square: ',r2)\n",
    "# print('R-square2: ',r22)\n",
    "\n",
    "# n = len(y_test)\n",
    "# p = 12\n",
    "# Adj_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "# Adj_r22 = 1-(1-r22)*(n-1)/(n-p-1)\n",
    "# print('Adj R-square: ',Adj_r2)\n",
    "# print('Adj R-square2: ',Adj_r22)\n",
    "\n",
    "plt.plot(history.history[\"loss\"],label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"],label=\"val_loss\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"No. Of Epochs\")\n",
    "plt.ylabel(\"mse score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9105857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
