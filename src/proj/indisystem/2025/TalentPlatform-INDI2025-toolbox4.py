import streamlit as st
import xarray as xr
import matplotlib.pyplot as plt
import cartopy.crs as ccrs
import cartopy.feature as cfeature
import tarfile
import os
import tempfile
import numpy as np
import pandas as pd
from pygwalker.api.streamlit import StreamlitRenderer

# ==========================================
# 1. Configuration & Caching
# ==========================================

# í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ë¨¼ì € í˜¸ì¶œ)
st.set_page_config(
    page_title="CM SAF R Toolbox (Python Ver)",
    page_icon="â˜ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì—°ì‚°ì ì •ì˜
OPERATOR_GROUPS = [
    "Hourly statistics", "Daily statistics", "Monthly statistics",
    "Seasonal statistics", "Annual statistics", "Temporal operators",
    "Climate Analysis"
]

OPERATORS = {
    "Hourly statistics": {"Hourly mean": "hourmean", "Hourly sum": "hoursum"},
    "Daily statistics": {"Diurnal means": "daymean", "Diurnal sums": "daysum", "Diurnal maxima": "daymax",
                         "Diurnal minima": "daymin"},
    "Monthly statistics": {"Monthly means": "monmean", "Monthly sums": "monsum", "Monthly anomalies": "mon.anomaly"},
    "Climate Analysis": {"Absolute map": "absolute_map", "Anomaly map": "anomaly_map",
                         "Time Series Plot": "time_series_plot"}
}

# ìƒ‰ìƒë§µ ì˜µì…˜
COLORMAPS = ['viridis', 'plasma', 'inferno', 'magma', 'cividis', 'coolwarm', 'jet', 'Spectral']


# ==========================================
# 2. Data Utilities (Cached)
# ==========================================

def identify_lat_lon_names(ds):
    """ë°ì´í„°ì…‹ì—ì„œ ìœ„ê²½ë„ ë³€ìˆ˜ëª… ì‹ë³„"""
    lat_name = None
    lon_name = None
    lat_candidates = ['lat', 'latitude', 'xlqc']
    lon_candidates = ['lon', 'longitude', 'xlgc']

    iterator = ds.variables if isinstance(ds, xr.Dataset) else ds.coords

    # 1. attrs ê¸°ë°˜ ê²€ìƒ‰
    for var_name in iterator:
        try:
            attrs = ds[var_name].attrs
            std_name = attrs.get('standard_name', '').lower()
            units = attrs.get('units', '').lower()
            if std_name == 'latitude' or 'degrees_north' in units: lat_name = var_name
            if std_name == 'longitude' or 'degrees_east' in units: lon_name = var_name
        except:
            continue

    # 2. ì´ë¦„ ê¸°ë°˜ ê²€ìƒ‰
    if not lat_name:
        for var_name in iterator:
            if str(var_name).lower() in lat_candidates: lat_name = var_name; break
    if not lon_name:
        for var_name in iterator:
            if str(var_name).lower() in lon_candidates: lon_name = var_name; break

    return lat_name, lon_name


def extract_tar(file_obj, extract_path):
    """TAR íŒŒì¼ ì••ì¶• í•´ì œ"""
    try:
        with tarfile.open(fileobj=file_obj, mode='r') as tar:
            tar.extractall(path=extract_path)
            return [f for f in os.listdir(extract_path) if f.endswith('.nc')]
    except Exception as e:
        st.error(f"Error extracting tar file: {e}")
        return []


@st.cache_resource(show_spinner=False)
def load_dataset(file_path):
    """NetCDF íŒŒì¼ ë¡œë“œ (ìºì‹± ì ìš©)"""
    try:
        ds = xr.open_dataset(file_path, decode_times=True)
        lat_name, lon_name = identify_lat_lon_names(ds)
        coords_to_set = [n for n in [lat_name, lon_name] if n and n in ds.data_vars]
        if coords_to_set:
            ds = ds.set_coords(coords_to_set)
        return ds
    except Exception as e:
        return None


@st.cache_data(show_spinner=False)
def calculate_statistics(file_path, var_name, operator_code):
    """í†µê³„ ì—°ì‚° ìˆ˜í–‰ (ë°ì´í„°ê°€ ì•„ë‹Œ íŒŒì¼ ê²½ë¡œë¥¼ í‚¤ë¡œ ìºì‹±)"""
    ds = load_dataset(file_path)
    if ds is None: return None

    da = ds[var_name]

    if operator_code == "monmean":
        return da.resample(time="1MS").mean(dim="time")
    elif operator_code == "monsum":
        return da.resample(time="1MS").sum(dim="time")
    elif operator_code == "daymean":
        return da.resample(time="1D").mean(dim="time")
    elif operator_code == "mon.anomaly":
        climatology = da.groupby("time.month").mean("time")
        return da.groupby("time.month") - climatology
    return da


# ==========================================
# 3. Plotting Utilities
# ==========================================

def plot_map(data_array, time_step=0, cmap='viridis', title="Map Plot"):
    # ë°ì´í„° ìŠ¬ë¼ì´ì‹±
    data_slice = data_array.isel(time=time_step) if 'time' in data_array.dims and data_array.sizes[
        'time'] > time_step else data_array.isel(time=0) if 'time' in data_array.dims else data_array

    lat_name, lon_name = identify_lat_lon_names(data_array)

    fig = plt.figure(figsize=(12, 7))
    ax = plt.axes(projection=ccrs.PlateCarree())
    ax.add_feature(cfeature.COASTLINE)
    ax.add_feature(cfeature.BORDERS, linestyle=':', alpha=0.5)
    ax.gridlines(draw_labels=True, linewidth=0.5, color='gray', alpha=0.3, linestyle='--')

    plot_kwargs = {
        'ax': ax, 'transform': ccrs.PlateCarree(),
        'cbar_kwargs': {'label': data_array.attrs.get('units', ''), 'shrink': 0.8},
        'cmap': cmap
    }
    if lat_name and lon_name:
        plot_kwargs.update({'x': lon_name, 'y': lat_name})

    try:
        data_slice.plot(**plot_kwargs)
        time_str = str(data_slice.time.values)[:10] if 'time' in data_slice.coords else ''
        ax.set_title(f"{title} | {time_str}", fontsize=14, fontweight='bold')
    except Exception as e:
        st.error(f"Plotting Error: {e}")

    return fig


def plot_timeseries(data_array, title="Time Series"):
    lat_name, lon_name = identify_lat_lon_names(data_array)
    dims_to_mean = [d for d in [lat_name, lon_name, 'lat', 'lon'] if d in data_array.dims]

    ts = data_array.mean(dim=dims_to_mean) if dims_to_mean else data_array

    fig, ax = plt.subplots(figsize=(12, 5))
    ts.plot.line(ax=ax, color='#1f77b4', linewidth=2)
    ax.set_title(f"Spatially Averaged Time Series: {title}", fontsize=14)
    ax.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)
    ax.set_ylabel(data_array.attrs.get('units', 'Value'))
    return fig


# ==========================================
# 4. Main Application
# ==========================================

def main():
    # --- Sidebar Navigation ---
    with st.sidebar:
        st.title("â˜ï¸ CM SAF Toolbox")
        st.markdown("Cloud & Radiation Analysis")

        step = st.radio(
            "Workflow Step",
            ["1. Prepare Data", "2. Analyze Data", "3. Visualize Results"],
            index=0
        )

        st.divider()
        st.caption("Based on CM SAF R Toolbox")
        st.caption("Powered by Streamlit & xarray")

    # --- Session State Init ---
    if 'nc_file_path' not in st.session_state: st.session_state.nc_file_path = None
    if 'processed_data' not in st.session_state: st.session_state.processed_data = None

    # --- STEP 1: PREPARE ---
    if step == "1. Prepare Data":
        st.title("ğŸ“‚ Data Preparation")
        st.markdown("ë¶„ì„í•  **NetCDF**(.nc) ë˜ëŠ” **Tar**(.tar) íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

        uploaded_file = st.file_uploader("Upload File", type=['tar', 'nc'], help="ìµœëŒ€ 200MB ê¶Œì¥")

        if uploaded_file:
            temp_dir = tempfile.mkdtemp()
            file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # TAR íŒŒì¼ ì²˜ë¦¬
            if uploaded_file.name.endswith('.tar'):
                with st.status("Extracting tar file...", expanded=True) as status:
                    nc_files = extract_tar(uploaded_file, temp_dir)
                    if nc_files:
                        status.update(label="Extraction Complete!", state="complete", expanded=False)
                        st.success(f"ğŸ“¦ {len(nc_files)} files extracted.")
                        selected_file = st.selectbox("Select a NetCDF file to load", nc_files)
                        st.session_state.nc_file_path = os.path.join(temp_dir, selected_file)
                    else:
                        status.update(label="Extraction Failed", state="error")
                        st.error("No .nc files found.")
            else:
                st.session_state.nc_file_path = file_path

            # ë°ì´í„°ì…‹ ë¡œë“œ ë° ë¯¸ë¦¬ë³´ê¸°
            if st.session_state.nc_file_path:
                ds = load_dataset(st.session_state.nc_file_path)
                if ds:
                    st.success(f"âœ… Loaded: {os.path.basename(st.session_state.nc_file_path)}")
                    with st.expander("ğŸ” View Dataset Metadata", expanded=True):
                        st.write(ds)
                        st.caption(f"Dimensions: {dict(ds.dims)}")

    # --- STEP 2: ANALYZE ---
    elif step == "2. Analyze Data":
        st.title("âš¡ Data Analysis")

        if not st.session_state.nc_file_path:
            st.warning("âš ï¸ 'Prepare Data' ë‹¨ê³„ì—ì„œ íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.stop()

        ds = load_dataset(st.session_state.nc_file_path)
        if not ds: st.stop()

        col1, col2 = st.columns([1, 2], gap="large")

        with col1:
            st.subheader("âš™ï¸ Settings")
            with st.container(border=True):
                selected_var = st.selectbox("Target Variable", list(ds.data_vars))
                op_group = st.selectbox("Operator Group", OPERATOR_GROUPS)

                op_list = list(OPERATORS.get(op_group, {}).keys())
                if op_list:
                    op_name = st.selectbox("Operator", op_list)
                    op_code = OPERATORS[op_group][op_name]
                else:
                    st.error("No operators available")
                    op_code = None

                if st.button("Run Calculation â–¶ï¸", type="primary", use_container_width=True):
                    if op_code:
                        with st.spinner("Processing..."):
                            # ìºì‹±ëœ í•¨ìˆ˜ í˜¸ì¶œ
                            result = calculate_statistics(st.session_state.nc_file_path, selected_var, op_code)
                            if result is not None:
                                st.session_state.processed_data = result
                                st.session_state.processed_data.name = f"{selected_var}_{op_code}"
                                st.rerun()  # ê²°ê³¼ ê°±ì‹ ì„ ìœ„í•´ ë¦¬ëŸ°

        with col2:
            st.subheader("ğŸ“Š Result Preview")
            if st.session_state.processed_data is not None:
                res = st.session_state.processed_data

                # ìš”ì•½ ë©”íŠ¸ë¦­ í‘œì‹œ
                m1, m2, m3 = st.columns(3)
                m1.metric("Min Value", f"{res.min().values:.2f}")
                m2.metric("Mean Value", f"{res.mean().values:.2f}")
                m3.metric("Max Value", f"{res.max().values:.2f}")

                st.success("Calculation completed successfully.")
                with st.expander("See raw data structure"):
                    st.write(res)
            else:
                st.info("ğŸ‘ˆ ì™¼ìª½ íŒ¨ë„ì—ì„œ ì—°ì‚°ì„ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ ì´ê³³ì— í‘œì‹œë©ë‹ˆë‹¤.")

    # --- STEP 3: VISUALIZE ---
    elif step == "3. Visualize Results":
        st.title("ğŸ¨ Visualization")

        data = st.session_state.processed_data
        if data is None:
            st.warning("âš ï¸ ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. 'Analyze Data' ë‹¨ê³„ì—ì„œ ì—°ì‚°ì„ ë¨¼ì € ìˆ˜í–‰í•´ì£¼ì„¸ìš”.")
            st.stop()

        # íƒ­ êµ¬ì„±ì„ í†µí•œ ì‹œê°í™” ë¶„ë¦¬
        tab1, tab2, tab3 = st.tabs(["ğŸŒ 2D Map", "ğŸ“ˆ Time Series", "ğŸ” Interactive Explorer"])

        with tab1:
            col_opt, col_plot = st.columns([1, 3])
            with col_opt:
                st.markdown("#### Map Options")
                cmap = st.selectbox("Colormap", COLORMAPS, index=0)

                time_idx = 0
                if 'time' in data.dims and data.sizes['time'] > 1:
                    time_len = data.sizes['time']
                    time_idx = st.slider("Time Step", 0, time_len - 1, 0, format="Idx %d")
                    st.caption(f"Date: {str(data.time.values[time_idx])[:10]}")

            with col_plot:
                fig = plot_map(data, time_idx, cmap, title=data.name)
                st.pyplot(fig)

        with tab2:
            st.markdown("#### Spatial Average Time Series")
            if 'time' in data.dims and data.sizes['time'] > 1:
                fig_ts = plot_timeseries(data, title=data.name)
                st.pyplot(fig_ts)
            else:
                st.info("ì‹œê³„ì—´ ì°¨ì›ì„ ê°€ì§„ ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤ (Time dimension size <= 1).")

        with tab3:
            st.markdown("#### PyGWalker Interactive Analysis")
            st.caption("Tableau-like drag-and-drop interface")

            if st.checkbox("Load PyGWalker (May take resources)", value=False):
                with st.spinner("Preparing interactive data..."):
                    try:
                        # ë°ì´í„°í”„ë ˆì„ ë³€í™˜ ìµœì í™” (ë„ˆë¬´ í¬ë©´ ìƒ˜í”Œë§)
                        df = data.to_dataframe(name='value').reset_index()
                        # if len(df) > 100000:
                        #     st.warning(f"Large dataset ({len(df)} rows). Using top 50,000 for performance.")
                        #     df = df.head(50000)

                        renderer = StreamlitRenderer(df, spec="./gw_config.json", spec_io_mode="RW")
                        renderer.explorer()
                    except Exception as e:
                        st.error(f"Error launching PyGWalker: {e}")

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (í•˜ë‹¨ ê³ ì •)
        st.divider()
        try:
            nc_bytes = data.to_netcdf()
            st.download_button(
                label="ğŸ“¥ Download Result (.nc)",
                data=nc_bytes,
                file_name=f"{data.name}_result.nc",
                mime="application/x-netcdf",
                type="primary"
            )
        except:
            pass


if __name__ == "__main__":
    main()