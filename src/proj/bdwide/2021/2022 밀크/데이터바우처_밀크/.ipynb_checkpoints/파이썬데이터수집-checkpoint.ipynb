{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 읽기 \n",
    "import twitter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "import snscrape\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "from time import sleep\n",
    "import datetime\n",
    "from datetime import datetime, date, time\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자 : 트위터 계정명,시작날짜(yyyy-mm-dd), 종료날짜(yyyy-mm-dd)\n",
    "# 리턴되는 결과 : 해당 계정의 트위터 결과 데이터 프레임 (url,time,id,content,text,username)\n",
    "# 계정 이름이 누락되는 경우 데이터 프레임이 반환되지 않고 대신 String 이 반환됨\n",
    "def read_tweet_list(keyword,startDay,endDay):\n",
    "    \n",
    "    tweets_list1 = []\n",
    "    tweets_df2 = pd.DataFrame(columns=['URL','Datetime', 'Tweet Id','Content', 'Username'])\n",
    "    \n",
    "    # 계정 정보가 잘못 들어온 경우 빈 데이터프레임을 반환 함\n",
    "    #if pd.isnull(twitterName) or twitterName == \"\":\n",
    "    #    return tweets_df2;\n",
    "        \n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "    #for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword + 'since :'+ startDay + 'until :'+ endDay + '').get_items()):\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(keyword + 'since:' +  startDay + ' until:' + \\\n",
    "                                                        endDay + ' -filter:links -filter:replies').get_items()):\n",
    "        tweets_list1.append([tweet.url, tweet.date, tweet.id, tweet.content, tweet.username])\n",
    "        #print(tweets_list1)\n",
    "        # Creating a dataframe from the tweets list above \n",
    "        tweets_df2 = pd.DataFrame(tweets_list1, columns=['URL','Datetime', 'Tweet Id','Content', 'Username'])\n",
    "    \n",
    "    return tweets_df2;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자 : 데이터 프레임 / 내용에 해당하는 컬럼의 이름\n",
    "# 리턴되는 결과 : RT 및 리플라이를 제외한 결과 트윗 데이터 프레임\n",
    "def remove_rt_reply(df,contentCol):\n",
    "    # content 의 가장 앞에 '@' 라는 문자열이  있는 경우 = Reply 로 판단.\n",
    "    # content 의 가장 앞에 'RT @' 라는 문자열이 있는 경우 = retweet 으로 판단.\n",
    "    # 결과적으로 내용 앞에 @ 가 있는 경우를 제거함으로서 리플라이 및 리트윗을 제거하고 남은 데이터 프레잉을 리턴함\n",
    "    rs = df.copy(deep=True)\n",
    "    row = -1\n",
    "    target = rs[contentCol]\n",
    "    \n",
    "    \n",
    "    rs['retflag'] = False\n",
    "    for i in target:\n",
    "        row = row + 1\n",
    "        \n",
    "        if(i[0:1] == \"@\" or i[0:2] == \"RT\"):\n",
    "            rs['retflag'][row] = True\n",
    "        else:\n",
    "            rs['retflag'][row] = False\n",
    "        \n",
    "    rs_L1 = rs[rs['retflag'] == False]\n",
    "    \n",
    "    del rs_L1['retflag']\n",
    "    rs_L1 = rs_L1.reset_index(drop=True)\n",
    "    \n",
    "    return rs_L1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인자 : 데이터 프레임 / 키워드 리스트 / 내용에 해당하는 컬럼 이름 / 헤시태그만 찾을 것인지 여부 / 키워드에 해당하는 내용이 없는 트윗 삭제 여부\n",
    "    # 리턴되는 결과 : 찾고자 하는 키워드가 있는 데이터가 존재하는 데이터 프레임\n",
    "        # 조건 1: isOnlyHashtag 가 True 인 경우 키워드 앞에 # 를 붙여서 헤시태그에 해당하는 내용만 찾음 (False 인 경우 순수하게 키워드 존재 여부로 찾아주)\n",
    "        # 조건 2 : isremove 가 True 인 경우 키워드를 찾지 못한 내용은 삭제한 후 리턴 (False 인경우 flag 만 붙여준 후 리턴)\n",
    "def search_keyword(df,keyword,contentCol,isOnlyHashtag,isremove):\n",
    "    \n",
    "    rs = df.copy(deep=True)\n",
    "    target = rs[contentCol]\n",
    "    keyword_low = []\n",
    "    # 오로지 헤시태그만 찾고자 하는 경우 키워드 앞에 # 을 붙이는 과정을 진행한다.\n",
    "    if(isOnlyHashtag == True):\n",
    "        for k in range(0,len(keyword),1):\n",
    "            keyword[k] = '#' + keyword[k]\n",
    "    else:\n",
    "        keyword = keyword\n",
    "        \n",
    "    for k in range(0,len(keyword),1):\n",
    "        keyword_low.append(keyword[k].lower())\n",
    "            \n",
    "    rs['findKeywordFlag'] = False\n",
    "    rs['findKeyword'] = ''\n",
    "    \n",
    "    row = -1\n",
    "    for i in target: # 콘텐츠의 내용\n",
    "        i_low = i.lower()\n",
    "        row = row + 1\n",
    "        for k in keyword_low: # 키워드 (대소문자는 구분하지 않음)\n",
    "            \n",
    "            if(i_low.find(k) >= 0): \n",
    "                rs['findKeywordFlag'][row] = True\n",
    "                key = rs['findKeyword'][row]\n",
    "                rs['findKeyword'][row] = rs['findKeyword'][row] +  k + '|'\n",
    "                \n",
    "    if(isremove == True):\n",
    "        rs_L1 = rs[rs['findKeywordFlag'] == True]\n",
    "        rs_L1 = rs_L1.reset_index(drop=True)\n",
    "    else:\n",
    "        rs_L1 = rs\n",
    "        \n",
    "    return rs_L1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AstraZeneca\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#st_day = \"2021-01-29\" # 시작날짜 지정\n",
    "#ed_day = \"2021-01-30\" # 마지막 날짜 지정\n",
    "\n",
    "st_day = date(2021, 2, 26)\n",
    "st_day = st_day.strftime('%Y-%m-%d')\n",
    "\n",
    "ed_day = date(2021, 3, 2)\n",
    "ed_day = ed_day.strftime('%Y-%m-%d')\n",
    "\n",
    "my_keyword = ['AstraZeneca'] # 찾고자 하는 키워드 지정\n",
    "\n",
    "output_file_name = \"./\"+str(my_keyword)+\"_after.csv\" # 출력할 파일 이름과 장소\n",
    "log_file_path = \"./log.txt\" # 로그 파일의 이름과 장소\n",
    "\n",
    "target_tweet_nmae = ['twittlions']\n",
    "\n",
    "append_mode = False \n",
    "\n",
    "for sid in my_keyword:\n",
    "    \n",
    "    print(sid)\n",
    "    # 트위터 수집 관련 예외처리 구분\n",
    "    try:\n",
    "        if pd.isnull(sid) or sid == \"\":\n",
    "            with open(log_file_path, \"a\") as file:\n",
    "                file.write(\"잘못된 키워드 입니다. 로그 저장 시각 : \" + str(datetime.now()) + \"\\n\")\n",
    "            file.close()\n",
    "            continue;\n",
    "            \n",
    "        result = read_tweet_list(sid,st_day,ed_day)\n",
    "        print(len(result))\n",
    "        with open(log_file_path, \"a\") as file:\n",
    "            file.write(sid + \" 키워드의 트위터 검색 완료! 총 \" + str(len(result)) + \"개의 트위터를 찾았습니다. 로그 저장 시각 : \" + str(datetime.now()) + \"\\n\")\n",
    "        file.close()\n",
    "    except:\n",
    "        with open(log_file_path, \"a\") as file:\n",
    "            file.write(sid + \" 키워드의 트위터 검색 중 오류가 발생하였습니다. 해당 아이디를 건너뜁니다. 로그 저장 시각 : \" + str(datetime.now()) + \"\\n\")\n",
    "        file.close()\n",
    "        continue;\n",
    "\n",
    "    \n",
    "    # 데이터가 존재하는 경우 쓰기 (라인단위)\n",
    "    if(len(result) > 0):\n",
    "                \n",
    "        if append_mode == False:\n",
    "            append_mode = True\n",
    "            result.to_csv(output_file_name + \".csv\",index=False,header=True)\n",
    "            \n",
    "        elif append_mode == True:\n",
    "            for i in range(len(result)):\n",
    "                result_L2.loc[[i]].to_csv(output_file_name,index=False,header=False,mode='a')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
